{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 114,
     "status": "ok",
     "timestamp": 1745478130397,
     "user": {
      "displayName": "Alice Jiang",
      "userId": "03912150214395170852"
     },
     "user_tz": -480
    },
    "id": "4_kyy4ggHIhe",
    "outputId": "2c0c56fc-2468-4163-dd45-c0facae7aa1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Time-Series-Library' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/thuml/Time-Series-Library.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1745478133200,
     "user": {
      "displayName": "Alice Jiang",
      "userId": "03912150214395170852"
     },
     "user_tz": -480
    },
    "id": "jxUaq8D1I0Ad",
    "outputId": "1f25197a-0f69-4b30-fcfa-eebc110af6cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Time-Series-Library\n"
     ]
    }
   ],
   "source": [
    "%cd /content/Time-Series-Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 112,
     "status": "ok",
     "timestamp": 1745478134059,
     "user": {
      "displayName": "Alice Jiang",
      "userId": "03912150214395170852"
     },
     "user_tz": -480
    },
    "id": "RcEWWvOUI2qd"
   },
   "outputs": [],
   "source": [
    "!mkdir -p ./dataset/traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2410,
     "status": "ok",
     "timestamp": 1745478137340,
     "user": {
      "displayName": "Alice Jiang",
      "userId": "03912150214395170852"
     },
     "user_tz": -480
    },
    "id": "Oca7u5K2I6Nz",
    "outputId": "8544bba3-c69f-4fae-d283-eff5391878ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
      "Requirement already satisfied: local-attention in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
      "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (1.23.5)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: patool in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
      "Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.11/dist-packages (1.10.1)\n",
      "Requirement already satisfied: sktime in /usr/local/lib/python3.11/dist-packages (0.37.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
      "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: pywavelets in /usr/local/lib/python3.11/dist-packages (1.8.0)\n",
      "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.11/dist-packages (2024.8.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==1.13.1) (4.13.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==1.13.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==1.13.1) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==1.13.1) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==1.13.1) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (75.2.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.45.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: scikit-base<0.13.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from sktime) (0.12.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy) (1.3.0)\n",
      "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (3.1.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (2025.3.2)\n",
      "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (6.0.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (0.12.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (8.6.1)\n",
      "Requirement already satisfied: dask-expr<1.2,>=1.1 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (1.1.11)\n",
      "Requirement already satisfied: pyarrow>=7.0.0 in /usr/local/lib/python3.11/dist-packages (from dask-expr<1.2,>=1.1->dask[dataframe]) (18.1.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=4.13.0->dask[dataframe]) (3.21.0)\n",
      "Requirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd>=1.4.0->dask[dataframe]) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install einops local-attention matplotlib numpy==1.23.5 pandas patool scikit-learn scipy==1.10.1 sktime sympy torch==1.13.1 tqdm pywavelets \"dask[dataframe]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 140792,
     "status": "ok",
     "timestamp": 1745478280540,
     "user": {
      "displayName": "Alice Jiang",
      "userId": "03912150214395170852"
     },
     "user_tz": -480
    },
    "id": "RuoGyQDnKFSc",
    "outputId": "c28415ab-67c6-4287-e698-c8ad5ca5e01f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting reformer-pytorch\n",
      "  Downloading reformer_pytorch-1.4.4-py3-none-any.whl.metadata (764 bytes)\n",
      "Collecting axial-positional-embedding>=0.1.0 (from reformer-pytorch)\n",
      "  Downloading axial_positional_embedding-0.3.12-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from reformer-pytorch) (0.8.1)\n",
      "Requirement already satisfied: local-attention in /usr/local/lib/python3.11/dist-packages (from reformer-pytorch) (1.10.0)\n",
      "Collecting product-key-memory (from reformer-pytorch)\n",
      "  Downloading product_key_memory-0.2.11-py3-none-any.whl.metadata (717 bytes)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from reformer-pytorch) (1.13.1)\n",
      "Collecting torch (from reformer-pytorch)\n",
      "  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->reformer-pytorch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->reformer-pytorch) (4.13.2)\n",
      "Collecting sympy>=1.13.3 (from torch->reformer-pytorch)\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->reformer-pytorch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->reformer-pytorch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->reformer-pytorch) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch->reformer-pytorch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch->reformer-pytorch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch->reformer-pytorch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch->reformer-pytorch)\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch->reformer-pytorch)\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch->reformer-pytorch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch->reformer-pytorch)\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch->reformer-pytorch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch->reformer-pytorch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch->reformer-pytorch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch->reformer-pytorch)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch->reformer-pytorch)\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch->reformer-pytorch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch->reformer-pytorch)\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.0 (from torch->reformer-pytorch)\n",
      "  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch->reformer-pytorch) (75.2.0)\n",
      "Collecting colt5-attention>=0.10.14 (from product-key-memory->reformer-pytorch)\n",
      "  Downloading CoLT5_attention-0.11.1-py3-none-any.whl.metadata (737 bytes)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from colt5-attention>=0.10.14->product-key-memory->reformer-pytorch) (24.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch->reformer-pytorch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->reformer-pytorch) (3.0.2)\n",
      "Downloading reformer_pytorch-1.4.4-py3-none-any.whl (16 kB)\n",
      "Downloading axial_positional_embedding-0.3.12-py3-none-any.whl (6.7 kB)\n",
      "Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m135.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading product_key_memory-0.2.11-py3-none-any.whl (6.5 kB)\n",
      "Downloading CoLT5_attention-0.11.1-py3-none-any.whl (18 kB)\n",
      "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m128.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, axial-positional-embedding, colt5-attention, product-key-memory, reformer-pytorch\n",
      "  Attempting uninstall: nvidia-cusparselt-cu12\n",
      "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
      "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
      "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.2.0\n",
      "    Uninstalling triton-3.2.0:\n",
      "      Successfully uninstalled triton-3.2.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.1\n",
      "    Uninstalling sympy-1.13.1:\n",
      "      Successfully uninstalled sympy-1.13.1\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1\n",
      "    Uninstalling torch-1.13.1:\n",
      "      Successfully uninstalled torch-1.13.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\n",
      "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed axial-positional-embedding-0.3.12 colt5-attention-0.11.1 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 product-key-memory-0.2.11 reformer-pytorch-1.4.4 sympy-1.13.3 torch-2.7.0 triton-3.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install reformer-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1745478356641,
     "user": {
      "displayName": "Alice Jiang",
      "userId": "03912150214395170852"
     },
     "user_tz": -480
    },
    "id": "VAIzKyC1K3Fr"
   },
   "outputs": [],
   "source": [
    "model_name=\"TimesNet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2697697,
     "status": "ok",
     "timestamp": 1745481055208,
     "user": {
      "displayName": "Alice Jiang",
      "userId": "03912150214395170852"
     },
     "user_tz": -480
    },
    "id": "pmbyEB33J0vX",
    "outputId": "5503fd74-9f68-4019-8f54-eb5c33216939"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Args in experiment:\n",
      "\u001b[1mBasic Config\u001b[0m\n",
      "  Task Name:          long_term_forecast  Is Training:        1                   \n",
      "  Model ID:           traffic_96_96       Model:              TimesNet            \n",
      "\n",
      "\u001b[1mData Loader\u001b[0m\n",
      "  Data:               custom              Root Path:          ./dataset/traffic/  \n",
      "  Data Path:          traffic.csv         Features:           M                   \n",
      "  Target:             OT                  Freq:               h                   \n",
      "  Checkpoints:        ./checkpoints/      \n",
      "\n",
      "\u001b[1mForecasting Task\u001b[0m\n",
      "  Seq Len:            96                  Label Len:          48                  \n",
      "  Pred Len:           96                  Seasonal Patterns:  Monthly             \n",
      "  Inverse:            0                   \n",
      "\n",
      "\u001b[1mModel Parameters\u001b[0m\n",
      "  Top k:              5                   Num Kernels:        6                   \n",
      "  Enc In:             862                 Dec In:             862                 \n",
      "  C Out:              862                 d model:            512                 \n",
      "  n heads:            8                   e layers:           2                   \n",
      "  d layers:           1                   d FF:               512                 \n",
      "  Moving Avg:         25                  Factor:             3                   \n",
      "  Distil:             1                   Dropout:            0.1                 \n",
      "  Embed:              timeF               Activation:         gelu                \n",
      "\n",
      "\u001b[1mRun Parameters\u001b[0m\n",
      "  Num Workers:        10                  Itr:                1                   \n",
      "  Train Epochs:       10                  Batch Size:         32                  \n",
      "  Patience:           3                   Learning Rate:      0.0001              \n",
      "  Des:                Exp                 Loss:               MSE                 \n",
      "  Lradj:              type1               Use Amp:            0                   \n",
      "\n",
      "\u001b[1mGPU\u001b[0m\n",
      "  Use GPU:            1                   GPU:                0                   \n",
      "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
      "\n",
      "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
      "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
      "\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_traffic_96_96_TimesNet_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df512_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12089\n",
      "val 1661\n",
      "test 3413\n",
      "\titers: 100, epoch: 1 | loss: 0.3998434\n",
      "\tspeed: 0.6086s/iter; left time: 2240.2912s\n",
      "\titers: 200, epoch: 1 | loss: 0.2873536\n",
      "\tspeed: 0.5946s/iter; left time: 2129.2888s\n",
      "\titers: 300, epoch: 1 | loss: 0.2470984\n",
      "\tspeed: 0.5913s/iter; left time: 2058.3474s\n",
      "Epoch: 1 cost time: 226.13192653656006\n",
      "Epoch: 1, Steps: 378 | Train Loss: 0.3616824 Vali Loss: 0.4797888 Test Loss: 0.6136519\n",
      "Validation loss decreased (inf --> 0.479789).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2262093\n",
      "\tspeed: 1.4440s/iter; left time: 4769.5544s\n",
      "\titers: 200, epoch: 2 | loss: 0.2351951\n",
      "\tspeed: 0.5961s/iter; left time: 1909.4394s\n",
      "\titers: 300, epoch: 2 | loss: 0.2303678\n",
      "\tspeed: 0.5941s/iter; left time: 1843.5610s\n",
      "Epoch: 2 cost time: 225.2866849899292\n",
      "Epoch: 2, Steps: 378 | Train Loss: 0.2411798 Vali Loss: 0.4657124 Test Loss: 0.6006999\n",
      "Validation loss decreased (0.479789 --> 0.465712).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2294922\n",
      "\tspeed: 1.4578s/iter; left time: 4264.0849s\n",
      "\titers: 200, epoch: 3 | loss: 0.2298688\n",
      "\tspeed: 0.5927s/iter; left time: 1674.3146s\n",
      "\titers: 300, epoch: 3 | loss: 0.2231381\n",
      "\tspeed: 0.5926s/iter; left time: 1614.9691s\n",
      "Epoch: 3 cost time: 224.50577640533447\n",
      "Epoch: 3, Steps: 378 | Train Loss: 0.2232521 Vali Loss: 0.4628115 Test Loss: 0.5998649\n",
      "Validation loss decreased (0.465712 --> 0.462811).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2218767\n",
      "\tspeed: 1.4542s/iter; left time: 3703.8066s\n",
      "\titers: 200, epoch: 4 | loss: 0.2143117\n",
      "\tspeed: 0.5919s/iter; left time: 1448.3541s\n",
      "\titers: 300, epoch: 4 | loss: 0.2307402\n",
      "\tspeed: 0.5923s/iter; left time: 1390.0946s\n",
      "Epoch: 4 cost time: 224.34019994735718\n",
      "Epoch: 4, Steps: 378 | Train Loss: 0.2156736 Vali Loss: 0.4542908 Test Loss: 0.5919346\n",
      "Validation loss decreased (0.462811 --> 0.454291).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2224755\n",
      "\tspeed: 1.4548s/iter; left time: 3155.3794s\n",
      "\titers: 200, epoch: 5 | loss: 0.2055325\n",
      "\tspeed: 0.5921s/iter; left time: 1225.1029s\n",
      "\titers: 300, epoch: 5 | loss: 0.2019693\n",
      "\tspeed: 0.5918s/iter; left time: 1165.3403s\n",
      "Epoch: 5 cost time: 224.28052496910095\n",
      "Epoch: 5, Steps: 378 | Train Loss: 0.2114264 Vali Loss: 0.4512872 Test Loss: 0.5899865\n",
      "Validation loss decreased (0.454291 --> 0.451287).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2167835\n",
      "\tspeed: 1.4548s/iter; left time: 2605.5304s\n",
      "\titers: 200, epoch: 6 | loss: 0.2037345\n",
      "\tspeed: 0.5921s/iter; left time: 1001.1825s\n",
      "\titers: 300, epoch: 6 | loss: 0.1891917\n",
      "\tspeed: 0.5921s/iter; left time: 942.1009s\n",
      "Epoch: 6 cost time: 224.36033844947815\n",
      "Epoch: 6, Steps: 378 | Train Loss: 0.2091411 Vali Loss: 0.4490768 Test Loss: 0.5888103\n",
      "Validation loss decreased (0.451287 --> 0.449077).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1998741\n",
      "\tspeed: 1.4536s/iter; left time: 2053.9287s\n",
      "\titers: 200, epoch: 7 | loss: 0.2229185\n",
      "\tspeed: 0.5928s/iter; left time: 778.3547s\n",
      "\titers: 300, epoch: 7 | loss: 0.2082544\n",
      "\tspeed: 0.5936s/iter; left time: 720.0476s\n",
      "Epoch: 7 cost time: 224.53885173797607\n",
      "Epoch: 7, Steps: 378 | Train Loss: 0.2078955 Vali Loss: 0.4488025 Test Loss: 0.5889685\n",
      "Validation loss decreased (0.449077 --> 0.448803).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2118509\n",
      "\tspeed: 1.4563s/iter; left time: 1507.3121s\n",
      "\titers: 200, epoch: 8 | loss: 0.1909509\n",
      "\tspeed: 0.5926s/iter; left time: 554.1231s\n",
      "\titers: 300, epoch: 8 | loss: 0.2114769\n",
      "\tspeed: 0.5931s/iter; left time: 495.2662s\n",
      "Epoch: 8 cost time: 224.5644133090973\n",
      "Epoch: 8, Steps: 378 | Train Loss: 0.2071662 Vali Loss: 0.4489055 Test Loss: 0.5894208\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.2218201\n",
      "\tspeed: 1.4400s/iter; left time: 946.0854s\n",
      "\titers: 200, epoch: 9 | loss: 0.2076486\n",
      "\tspeed: 0.5932s/iter; left time: 330.4220s\n",
      "\titers: 300, epoch: 9 | loss: 0.2078833\n",
      "\tspeed: 0.5928s/iter; left time: 270.8986s\n",
      "Epoch: 9 cost time: 224.5988631248474\n",
      "Epoch: 9, Steps: 378 | Train Loss: 0.2068282 Vali Loss: 0.4496487 Test Loss: 0.5897784\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.2238369\n",
      "\tspeed: 1.4392s/iter; left time: 401.5469s\n",
      "\titers: 200, epoch: 10 | loss: 0.2027369\n",
      "\tspeed: 0.5925s/iter; left time: 106.0631s\n",
      "\titers: 300, epoch: 10 | loss: 0.2083037\n",
      "\tspeed: 0.5932s/iter; left time: 46.8624s\n",
      "Epoch: 10 cost time: 224.60381960868835\n",
      "Epoch: 10, Steps: 378 | Train Loss: 0.2066110 Vali Loss: 0.4496819 Test Loss: 0.5902095\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_traffic_96_96_TimesNet_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df512_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 3413\n",
      "test shape: (3413, 96, 862) (3413, 96, 862)\n",
      "test shape: (3413, 96, 862) (3413, 96, 862)\n",
      "mse:0.5898281335830688, mae:0.31433597207069397, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./dataset/traffic/ \\\n",
    "  --data_path traffic.csv \\\n",
    "  --model_id traffic_96_96 \\\n",
    "  --model $model_name \\\n",
    "  --data custom \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 862 \\\n",
    "  --dec_in 862 \\\n",
    "  --c_out 862 \\\n",
    "  --d_model 512 \\\n",
    "  --d_ff 512 \\\n",
    "  --top_k 5 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5B9g4DYex4l"
   },
   "source": [
    "# missing rate = 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14626,
     "status": "ok",
     "timestamp": 1745481661867,
     "user": {
      "displayName": "Alice Jiang",
      "userId": "03912150214395170852"
     },
     "user_tz": -480
    },
    "id": "Ja9L3F-0XLZU",
    "outputId": "5b155656-575d-490e-f3bf-f211ae4192da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-5d6918a09128>:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n",
      "<ipython-input-8-5d6918a09128>:20: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "missing_rate = 0.1\n",
    "np.random.seed(42)\n",
    "\n",
    "original_file = './dataset/traffic/traffic.csv'\n",
    "missing_file = './dataset/traffic/traffic_missing_10.csv'\n",
    "\n",
    "df = pd.read_csv(original_file)\n",
    "\n",
    "cols = [col for col in df.columns if col != 'date']\n",
    "for col in cols:\n",
    "    n_missing = int(len(df) * missing_rate)\n",
    "    missing_indices = np.random.choice(df.index, n_missing, replace=False)\n",
    "    df.loc[missing_indices, col] = np.nan\n",
    "\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "df.to_csv(missing_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2693076,
     "status": "ok",
     "timestamp": 1745484361524,
     "user": {
      "displayName": "Alice Jiang",
      "userId": "03912150214395170852"
     },
     "user_tz": -480
    },
    "id": "cQIDaoFQXTzU",
    "outputId": "3cd27780-7df7-468b-ae2e-36738e9960ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Args in experiment:\n",
      "\u001b[1mBasic Config\u001b[0m\n",
      "  Task Name:          long_term_forecast  Is Training:        1                   \n",
      "  Model ID:           traffic_missing10_96_96Model:              TimesNet            \n",
      "\n",
      "\u001b[1mData Loader\u001b[0m\n",
      "  Data:               custom              Root Path:          ./dataset/traffic/  \n",
      "  Data Path:          traffic_missing_10.csvFeatures:           M                   \n",
      "  Target:             OT                  Freq:               h                   \n",
      "  Checkpoints:        ./checkpoints/      \n",
      "\n",
      "\u001b[1mForecasting Task\u001b[0m\n",
      "  Seq Len:            96                  Label Len:          48                  \n",
      "  Pred Len:           96                  Seasonal Patterns:  Monthly             \n",
      "  Inverse:            0                   \n",
      "\n",
      "\u001b[1mModel Parameters\u001b[0m\n",
      "  Top k:              5                   Num Kernels:        6                   \n",
      "  Enc In:             862                 Dec In:             862                 \n",
      "  C Out:              862                 d model:            512                 \n",
      "  n heads:            8                   e layers:           2                   \n",
      "  d layers:           1                   d FF:               512                 \n",
      "  Moving Avg:         25                  Factor:             3                   \n",
      "  Distil:             1                   Dropout:            0.1                 \n",
      "  Embed:              timeF               Activation:         gelu                \n",
      "\n",
      "\u001b[1mRun Parameters\u001b[0m\n",
      "  Num Workers:        10                  Itr:                1                   \n",
      "  Train Epochs:       10                  Batch Size:         32                  \n",
      "  Patience:           3                   Learning Rate:      0.0001              \n",
      "  Des:                MissingTest         Loss:               MSE                 \n",
      "  Lradj:              type1               Use Amp:            0                   \n",
      "\n",
      "\u001b[1mGPU\u001b[0m\n",
      "  Use GPU:            1                   GPU:                0                   \n",
      "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
      "\n",
      "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
      "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
      "\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_traffic_missing10_96_96_TimesNet_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df512_expand2_dc4_fc3_ebtimeF_dtTrue_MissingTest_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12089\n",
      "val 1661\n",
      "test 3413\n",
      "\titers: 100, epoch: 1 | loss: 0.4323019\n",
      "\tspeed: 0.6039s/iter; left time: 2223.0052s\n",
      "\titers: 200, epoch: 1 | loss: 0.3025244\n",
      "\tspeed: 0.5937s/iter; left time: 2126.2178s\n",
      "\titers: 300, epoch: 1 | loss: 0.2670541\n",
      "\tspeed: 0.5918s/iter; left time: 2060.0147s\n",
      "Epoch: 1 cost time: 225.6112036705017\n",
      "Epoch: 1, Steps: 378 | Train Loss: 0.3764733 Vali Loss: 0.4980083 Test Loss: 0.6349432\n",
      "Validation loss decreased (inf --> 0.498008).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2537655\n",
      "\tspeed: 1.4471s/iter; left time: 4779.6645s\n",
      "\titers: 200, epoch: 2 | loss: 0.2548761\n",
      "\tspeed: 0.5962s/iter; left time: 1909.7782s\n",
      "\titers: 300, epoch: 2 | loss: 0.2471858\n",
      "\tspeed: 0.5962s/iter; left time: 1850.1310s\n",
      "Epoch: 2 cost time: 225.73645639419556\n",
      "Epoch: 2, Steps: 378 | Train Loss: 0.2594489 Vali Loss: 0.4821855 Test Loss: 0.6208888\n",
      "Validation loss decreased (0.498008 --> 0.482186).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2498043\n",
      "\tspeed: 1.4601s/iter; left time: 4270.9172s\n",
      "\titers: 200, epoch: 3 | loss: 0.2516703\n",
      "\tspeed: 0.5965s/iter; left time: 1685.0121s\n",
      "\titers: 300, epoch: 3 | loss: 0.2418380\n",
      "\tspeed: 0.5955s/iter; left time: 1622.8645s\n",
      "Epoch: 3 cost time: 225.64339590072632\n",
      "Epoch: 3, Steps: 378 | Train Loss: 0.2419892 Vali Loss: 0.4825470 Test Loss: 0.6221538\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2415813\n",
      "\tspeed: 1.4417s/iter; left time: 3671.8829s\n",
      "\titers: 200, epoch: 4 | loss: 0.2314114\n",
      "\tspeed: 0.5925s/iter; left time: 1449.7927s\n",
      "\titers: 300, epoch: 4 | loss: 0.2513324\n",
      "\tspeed: 0.5923s/iter; left time: 1390.1738s\n",
      "Epoch: 4 cost time: 224.39700508117676\n",
      "Epoch: 4, Steps: 378 | Train Loss: 0.2346518 Vali Loss: 0.4742650 Test Loss: 0.6146628\n",
      "Validation loss decreased (0.482186 --> 0.474265).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2403504\n",
      "\tspeed: 1.4575s/iter; left time: 3161.3882s\n",
      "\titers: 200, epoch: 5 | loss: 0.2259887\n",
      "\tspeed: 0.5919s/iter; left time: 1224.7218s\n",
      "\titers: 300, epoch: 5 | loss: 0.2208218\n",
      "\tspeed: 0.5919s/iter; left time: 1165.5148s\n",
      "Epoch: 5 cost time: 224.29391837120056\n",
      "Epoch: 5, Steps: 378 | Train Loss: 0.2306100 Vali Loss: 0.4711678 Test Loss: 0.6135198\n",
      "Validation loss decreased (0.474265 --> 0.471168).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2354916\n",
      "\tspeed: 1.4574s/iter; left time: 2610.1961s\n",
      "\titers: 200, epoch: 6 | loss: 0.2254680\n",
      "\tspeed: 0.5924s/iter; left time: 1001.6909s\n",
      "\titers: 300, epoch: 6 | loss: 0.2075346\n",
      "\tspeed: 0.5923s/iter; left time: 942.4091s\n",
      "Epoch: 6 cost time: 224.33602476119995\n",
      "Epoch: 6, Steps: 378 | Train Loss: 0.2284562 Vali Loss: 0.4697477 Test Loss: 0.6121678\n",
      "Validation loss decreased (0.471168 --> 0.469748).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2181318\n",
      "\tspeed: 1.4558s/iter; left time: 2057.0974s\n",
      "\titers: 200, epoch: 7 | loss: 0.2438178\n",
      "\tspeed: 0.5924s/iter; left time: 777.7919s\n",
      "\titers: 300, epoch: 7 | loss: 0.2290499\n",
      "\tspeed: 0.5924s/iter; left time: 718.6158s\n",
      "Epoch: 7 cost time: 224.31786680221558\n",
      "Epoch: 7, Steps: 378 | Train Loss: 0.2272902 Vali Loss: 0.4690537 Test Loss: 0.6118007\n",
      "Validation loss decreased (0.469748 --> 0.469054).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2310659\n",
      "\tspeed: 1.4551s/iter; left time: 1505.9902s\n",
      "\titers: 200, epoch: 8 | loss: 0.2093401\n",
      "\tspeed: 0.5924s/iter; left time: 553.8522s\n",
      "\titers: 300, epoch: 8 | loss: 0.2294906\n",
      "\tspeed: 0.5922s/iter; left time: 494.4786s\n",
      "Epoch: 8 cost time: 224.34151935577393\n",
      "Epoch: 8, Steps: 378 | Train Loss: 0.2265909 Vali Loss: 0.4688315 Test Loss: 0.6117579\n",
      "Validation loss decreased (0.469054 --> 0.468832).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.2436490\n",
      "\tspeed: 1.4568s/iter; left time: 957.1275s\n",
      "\titers: 200, epoch: 9 | loss: 0.2271725\n",
      "\tspeed: 0.5913s/iter; left time: 329.3704s\n",
      "\titers: 300, epoch: 9 | loss: 0.2266393\n",
      "\tspeed: 0.5915s/iter; left time: 270.3001s\n",
      "Epoch: 9 cost time: 224.0644268989563\n",
      "Epoch: 9, Steps: 378 | Train Loss: 0.2262723 Vali Loss: 0.4697693 Test Loss: 0.6121053\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.2445102\n",
      "\tspeed: 1.4395s/iter; left time: 401.6310s\n",
      "\titers: 200, epoch: 10 | loss: 0.2222160\n",
      "\tspeed: 0.5914s/iter; left time: 105.8631s\n",
      "\titers: 300, epoch: 10 | loss: 0.2278502\n",
      "\tspeed: 0.5925s/iter; left time: 46.8059s\n",
      "Epoch: 10 cost time: 224.24329018592834\n",
      "Epoch: 10, Steps: 378 | Train Loss: 0.2260774 Vali Loss: 0.4698325 Test Loss: 0.6125515\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast_traffic_missing10_96_96_TimesNet_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df512_expand2_dc4_fc3_ebtimeF_dtTrue_MissingTest_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 3413\n",
      "test shape: (3413, 96, 862) (3413, 96, 862)\n",
      "test shape: (3413, 96, 862) (3413, 96, 862)\n",
      "mse:0.612663209438324, mae:0.3295629918575287, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./dataset/traffic/ \\\n",
    "  --data_path traffic_missing_10.csv \\\n",
    "  --model_id traffic_missing10_96_96 \\\n",
    "  --model TimesNet \\\n",
    "  --data custom \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 862 \\\n",
    "  --dec_in 862 \\\n",
    "  --c_out 862 \\\n",
    "  --d_model 512 \\\n",
    "  --d_ff 512 \\\n",
    "  --top_k 5 \\\n",
    "  --des 'MissingTest' \\\n",
    "  --itr 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUKi6TBBem93"
   },
   "source": [
    "# missing rate = 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13933,
     "status": "ok",
     "timestamp": 1745484436097,
     "user": {
      "displayName": "Alice Jiang",
      "userId": "03912150214395170852"
     },
     "user_tz": -480
    },
    "id": "uWNeaAJnncaf",
    "outputId": "bcccf926-133d-48eb-f892-909502e92fc1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-b045e24d27ea>:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n",
      "<ipython-input-10-b045e24d27ea>:20: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "missing_rate = 0.05\n",
    "np.random.seed(42)\n",
    "\n",
    "original_file = './dataset/traffic/traffic.csv'\n",
    "missing_file = './dataset/traffic/traffic_missing_005.csv'\n",
    "\n",
    "df = pd.read_csv(original_file)\n",
    "\n",
    "cols = [col for col in df.columns if col != 'date']\n",
    "for col in cols:\n",
    "    n_missing = int(len(df) * missing_rate)\n",
    "    missing_indices = np.random.choice(df.index, n_missing, replace=False)\n",
    "    df.loc[missing_indices, col] = np.nan\n",
    "\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "df.to_csv(missing_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2700318,
     "status": "ok",
     "timestamp": 1745487162810,
     "user": {
      "displayName": "Alice Jiang",
      "userId": "03912150214395170852"
     },
     "user_tz": -480
    },
    "id": "64T7ABfxnnto",
    "outputId": "a17b6d26-9190-4e75-bf0b-a61f8d5132b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Args in experiment:\n",
      "\u001b[1mBasic Config\u001b[0m\n",
      "  Task Name:          long_term_forecast  Is Training:        1                   \n",
      "  Model ID:           traffic_missing005_96_96Model:              TimesNet            \n",
      "\n",
      "\u001b[1mData Loader\u001b[0m\n",
      "  Data:               custom              Root Path:          ./dataset/traffic/  \n",
      "  Data Path:          traffic_missing_005.csvFeatures:           M                   \n",
      "  Target:             OT                  Freq:               h                   \n",
      "  Checkpoints:        ./checkpoints/      \n",
      "\n",
      "\u001b[1mForecasting Task\u001b[0m\n",
      "  Seq Len:            96                  Label Len:          48                  \n",
      "  Pred Len:           96                  Seasonal Patterns:  Monthly             \n",
      "  Inverse:            0                   \n",
      "\n",
      "\u001b[1mModel Parameters\u001b[0m\n",
      "  Top k:              5                   Num Kernels:        6                   \n",
      "  Enc In:             862                 Dec In:             862                 \n",
      "  C Out:              862                 d model:            512                 \n",
      "  n heads:            8                   e layers:           2                   \n",
      "  d layers:           1                   d FF:               512                 \n",
      "  Moving Avg:         25                  Factor:             3                   \n",
      "  Distil:             1                   Dropout:            0.1                 \n",
      "  Embed:              timeF               Activation:         gelu                \n",
      "\n",
      "\u001b[1mRun Parameters\u001b[0m\n",
      "  Num Workers:        10                  Itr:                1                   \n",
      "  Train Epochs:       10                  Batch Size:         32                  \n",
      "  Patience:           3                   Learning Rate:      0.0001              \n",
      "  Des:                MissingTest         Loss:               MSE                 \n",
      "  Lradj:              type1               Use Amp:            0                   \n",
      "\n",
      "\u001b[1mGPU\u001b[0m\n",
      "  Use GPU:            1                   GPU:                0                   \n",
      "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
      "\n",
      "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
      "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
      "\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_traffic_missing005_96_96_TimesNet_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df512_expand2_dc4_fc3_ebtimeF_dtTrue_MissingTest_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12089\n",
      "val 1661\n",
      "test 3413\n",
      "\titers: 100, epoch: 1 | loss: 0.4162412\n",
      "\tspeed: 0.6050s/iter; left time: 2226.8839s\n",
      "\titers: 200, epoch: 1 | loss: 0.2940174\n",
      "\tspeed: 0.5950s/iter; left time: 2130.5366s\n",
      "\titers: 300, epoch: 1 | loss: 0.2566460\n",
      "\tspeed: 0.5924s/iter; left time: 2062.0035s\n",
      "Epoch: 1 cost time: 225.94687938690186\n",
      "Epoch: 1, Steps: 378 | Train Loss: 0.3686424 Vali Loss: 0.4915561 Test Loss: 0.6276888\n",
      "Validation loss decreased (inf --> 0.491556).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2354299\n",
      "\tspeed: 1.4441s/iter; left time: 4769.8596s\n",
      "\titers: 200, epoch: 2 | loss: 0.2447220\n",
      "\tspeed: 0.5959s/iter; left time: 1908.7867s\n",
      "\titers: 300, epoch: 2 | loss: 0.2382697\n",
      "\tspeed: 0.5964s/iter; left time: 1850.7669s\n",
      "Epoch: 2 cost time: 225.91188669204712\n",
      "Epoch: 2, Steps: 378 | Train Loss: 0.2500338 Vali Loss: 0.4752634 Test Loss: 0.6124564\n",
      "Validation loss decreased (0.491556 --> 0.475263).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2408562\n",
      "\tspeed: 1.4652s/iter; left time: 4285.7678s\n",
      "\titers: 200, epoch: 3 | loss: 0.2403791\n",
      "\tspeed: 0.5958s/iter; left time: 1683.2193s\n",
      "\titers: 300, epoch: 3 | loss: 0.2334519\n",
      "\tspeed: 0.5953s/iter; left time: 1622.2736s\n",
      "Epoch: 3 cost time: 225.64297795295715\n",
      "Epoch: 3, Steps: 378 | Train Loss: 0.2325504 Vali Loss: 0.4736300 Test Loss: 0.6125597\n",
      "Validation loss decreased (0.475263 --> 0.473630).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2311577\n",
      "\tspeed: 1.4604s/iter; left time: 3719.6020s\n",
      "\titers: 200, epoch: 4 | loss: 0.2236510\n",
      "\tspeed: 0.5949s/iter; left time: 1455.6151s\n",
      "\titers: 300, epoch: 4 | loss: 0.2411955\n",
      "\tspeed: 0.5947s/iter; left time: 1395.7506s\n",
      "Epoch: 4 cost time: 225.15910744667053\n",
      "Epoch: 4, Steps: 378 | Train Loss: 0.2250074 Vali Loss: 0.4658001 Test Loss: 0.6047680\n",
      "Validation loss decreased (0.473630 --> 0.465800).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2311130\n",
      "\tspeed: 1.4558s/iter; left time: 3157.5939s\n",
      "\titers: 200, epoch: 5 | loss: 0.2152940\n",
      "\tspeed: 0.5930s/iter; left time: 1226.9902s\n",
      "\titers: 300, epoch: 5 | loss: 0.2111342\n",
      "\tspeed: 0.5934s/iter; left time: 1168.4931s\n",
      "Epoch: 5 cost time: 224.70630311965942\n",
      "Epoch: 5, Steps: 378 | Train Loss: 0.2208912 Vali Loss: 0.4629105 Test Loss: 0.6024798\n",
      "Validation loss decreased (0.465800 --> 0.462911).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2260887\n",
      "\tspeed: 1.4824s/iter; left time: 2654.9743s\n",
      "\titers: 200, epoch: 6 | loss: 0.2142739\n",
      "\tspeed: 0.5938s/iter; left time: 1004.1840s\n",
      "\titers: 300, epoch: 6 | loss: 0.1981002\n",
      "\tspeed: 0.5934s/iter; left time: 944.1396s\n",
      "Epoch: 6 cost time: 224.7771453857422\n",
      "Epoch: 6, Steps: 378 | Train Loss: 0.2186843 Vali Loss: 0.4614103 Test Loss: 0.6018876\n",
      "Validation loss decreased (0.462911 --> 0.461410).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2090141\n",
      "\tspeed: 1.4583s/iter; left time: 2060.6395s\n",
      "\titers: 200, epoch: 7 | loss: 0.2343019\n",
      "\tspeed: 0.5930s/iter; left time: 778.5501s\n",
      "\titers: 300, epoch: 7 | loss: 0.2182225\n",
      "\tspeed: 0.5935s/iter; left time: 719.8903s\n",
      "Epoch: 7 cost time: 224.59652161598206\n",
      "Epoch: 7, Steps: 378 | Train Loss: 0.2174929 Vali Loss: 0.4610306 Test Loss: 0.6019324\n",
      "Validation loss decreased (0.461410 --> 0.461031).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2209702\n",
      "\tspeed: 1.4583s/iter; left time: 1509.2987s\n",
      "\titers: 200, epoch: 8 | loss: 0.2000703\n",
      "\tspeed: 0.5927s/iter; left time: 554.1810s\n",
      "\titers: 300, epoch: 8 | loss: 0.2201743\n",
      "\tspeed: 0.5936s/iter; left time: 495.6937s\n",
      "Epoch: 8 cost time: 224.62844157218933\n",
      "Epoch: 8, Steps: 378 | Train Loss: 0.2167821 Vali Loss: 0.4607913 Test Loss: 0.6016253\n",
      "Validation loss decreased (0.461031 --> 0.460791).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.2328554\n",
      "\tspeed: 1.4575s/iter; left time: 957.5987s\n",
      "\titers: 200, epoch: 9 | loss: 0.2174032\n",
      "\tspeed: 0.5932s/iter; left time: 330.4166s\n",
      "\titers: 300, epoch: 9 | loss: 0.2168167\n",
      "\tspeed: 0.5932s/iter; left time: 271.1091s\n",
      "Epoch: 9 cost time: 224.61376643180847\n",
      "Epoch: 9, Steps: 378 | Train Loss: 0.2164555 Vali Loss: 0.4617114 Test Loss: 0.6021105\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.2338817\n",
      "\tspeed: 1.4407s/iter; left time: 401.9421s\n",
      "\titers: 200, epoch: 10 | loss: 0.2132865\n",
      "\tspeed: 0.5925s/iter; left time: 106.0555s\n",
      "\titers: 300, epoch: 10 | loss: 0.2180775\n",
      "\tspeed: 0.5931s/iter; left time: 46.8536s\n",
      "Epoch: 10 cost time: 224.58262515068054\n",
      "Epoch: 10, Steps: 378 | Train Loss: 0.2162496 Vali Loss: 0.4617999 Test Loss: 0.6026572\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast_traffic_missing005_96_96_TimesNet_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df512_expand2_dc4_fc3_ebtimeF_dtTrue_MissingTest_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 3413\n",
      "test shape: (3413, 96, 862) (3413, 96, 862)\n",
      "test shape: (3413, 96, 862) (3413, 96, 862)\n",
      "mse:0.6025060415267944, mae:0.32203665375709534, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./dataset/traffic/ \\\n",
    "  --data_path traffic_missing_005.csv \\\n",
    "  --model_id traffic_missing005_96_96 \\\n",
    "  --model TimesNet \\\n",
    "  --data custom \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 862 \\\n",
    "  --dec_in 862 \\\n",
    "  --c_out 862 \\\n",
    "  --d_model 512 \\\n",
    "  --d_ff 512 \\\n",
    "  --top_k 5 \\\n",
    "  --des 'MissingTest' \\\n",
    "  --itr 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tSCRcL1eUpP"
   },
   "source": [
    "# missing rate = 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13848,
     "status": "ok",
     "timestamp": 1745487615045,
     "user": {
      "displayName": "Alice Jiang",
      "userId": "03912150214395170852"
     },
     "user_tz": -480
    },
    "id": "3O9R6gf90cx5",
    "outputId": "05df1a04-efad-4e16-88e1-0a2f21d22d17"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-9969c221f888>:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n",
      "<ipython-input-12-9969c221f888>:20: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "missing_rate = 0.15\n",
    "np.random.seed(42)\n",
    "\n",
    "original_file = './dataset/traffic/traffic.csv'\n",
    "missing_file = './dataset/traffic/traffic_missing_015.csv'\n",
    "\n",
    "df = pd.read_csv(original_file)\n",
    "\n",
    "cols = [col for col in df.columns if col != 'date']\n",
    "for col in cols:\n",
    "    n_missing = int(len(df) * missing_rate)\n",
    "    missing_indices = np.random.choice(df.index, n_missing, replace=False)\n",
    "    df.loc[missing_indices, col] = np.nan\n",
    "\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "df.to_csv(missing_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1985090,
     "status": "ok",
     "timestamp": 1744881205006,
     "user": {
      "displayName": "Alice Jiang",
      "userId": "03912150214395170852"
     },
     "user_tz": -480
    },
    "id": "0N4-bcmF2t_z",
    "outputId": "5ba10c1f-9b30-4332-c890-efb7878106da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Args in experiment:\n",
      "\u001b[1mBasic Config\u001b[0m\n",
      "  Task Name:          long_term_forecast  Is Training:        1                   \n",
      "  Model ID:           traffic_missing015_96_96Model:              TimesNet            \n",
      "\n",
      "\u001b[1mData Loader\u001b[0m\n",
      "  Data:               custom              Root Path:          ./dataset/traffic/  \n",
      "  Data Path:          traffic_missing_015.csvFeatures:           M                   \n",
      "  Target:             OT                  Freq:               h                   \n",
      "  Checkpoints:        ./checkpoints/      \n",
      "\n",
      "\u001b[1mForecasting Task\u001b[0m\n",
      "  Seq Len:            96                  Label Len:          48                  \n",
      "  Pred Len:           96                  Seasonal Patterns:  Monthly             \n",
      "  Inverse:            0                   \n",
      "\n",
      "\u001b[1mModel Parameters\u001b[0m\n",
      "  Top k:              5                   Num Kernels:        6                   \n",
      "  Enc In:             862                 Dec In:             862                 \n",
      "  C Out:              862                 d model:            512                 \n",
      "  n heads:            8                   e layers:           2                   \n",
      "  d layers:           1                   d FF:               512                 \n",
      "  Moving Avg:         25                  Factor:             3                   \n",
      "  Distil:             1                   Dropout:            0.1                 \n",
      "  Embed:              timeF               Activation:         gelu                \n",
      "\n",
      "\u001b[1mRun Parameters\u001b[0m\n",
      "  Num Workers:        10                  Itr:                1                   \n",
      "  Train Epochs:       10                  Batch Size:         32                  \n",
      "  Patience:           3                   Learning Rate:      0.0001              \n",
      "  Des:                MissingTest         Loss:               MSE                 \n",
      "  Lradj:              type1               Use Amp:            0                   \n",
      "\n",
      "\u001b[1mGPU\u001b[0m\n",
      "  Use GPU:            1                   GPU:                0                   \n",
      "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
      "\n",
      "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
      "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
      "\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_traffic_missing015_96_96_TimesNet_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df512_expand2_dc4_fc3_ebtimeF_dtTrue_MissingTest_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12089\n",
      "val 1661\n",
      "test 3413\n",
      "\titers: 100, epoch: 1 | loss: 0.4186839\n",
      "\tspeed: 0.6238s/iter; left time: 2296.1129s\n",
      "\titers: 200, epoch: 1 | loss: 0.3127138\n",
      "\tspeed: 0.6121s/iter; left time: 2191.8875s\n",
      "\titers: 300, epoch: 1 | loss: 0.2751623\n",
      "\tspeed: 0.6145s/iter; left time: 2138.9080s\n",
      "Epoch: 1 cost time: 233.3625843524933\n",
      "Epoch: 1, Steps: 378 | Train Loss: 0.3828789 Vali Loss: 0.5011301 Test Loss: 0.6459841\n",
      "Validation loss decreased (inf --> 0.501130).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2615279\n",
      "\tspeed: 1.5168s/iter; left time: 5010.0753s\n",
      "\titers: 200, epoch: 2 | loss: 0.2648058\n",
      "\tspeed: 0.6160s/iter; left time: 1972.9709s\n",
      "\titers: 300, epoch: 2 | loss: 0.2568141\n",
      "\tspeed: 0.6163s/iter; left time: 1912.2423s\n",
      "Epoch: 2 cost time: 233.2973132133484\n",
      "Epoch: 2, Steps: 378 | Train Loss: 0.2697070 Vali Loss: 0.4850107 Test Loss: 0.6286806\n",
      "Validation loss decreased (0.501130 --> 0.485011).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2597540\n",
      "\tspeed: 1.5370s/iter; left time: 4495.7820s\n",
      "\titers: 200, epoch: 3 | loss: 0.2629308\n",
      "\tspeed: 0.6165s/iter; left time: 1741.6482s\n",
      "\titers: 300, epoch: 3 | loss: 0.2525508\n",
      "\tspeed: 0.6170s/iter; left time: 1681.1910s\n",
      "Epoch: 3 cost time: 233.6113920211792\n",
      "Epoch: 3, Steps: 378 | Train Loss: 0.2527712 Vali Loss: 0.4851603 Test Loss: 0.6315928\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2530349\n",
      "\tspeed: 1.5229s/iter; left time: 3878.7764s\n",
      "\titers: 200, epoch: 4 | loss: 0.2410840\n",
      "\tspeed: 0.6178s/iter; left time: 1511.7426s\n",
      "\titers: 300, epoch: 4 | loss: 0.2638333\n",
      "\tspeed: 0.6179s/iter; left time: 1450.1504s\n",
      "Epoch: 4 cost time: 234.14291858673096\n",
      "Epoch: 4, Steps: 378 | Train Loss: 0.2455222 Vali Loss: 0.4757649 Test Loss: 0.6235353\n",
      "Validation loss decreased (0.485011 --> 0.475765).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2514979\n",
      "\tspeed: 1.5456s/iter; left time: 3352.3708s\n",
      "\titers: 200, epoch: 5 | loss: 0.2368959\n",
      "\tspeed: 0.6187s/iter; left time: 1280.0881s\n",
      "\titers: 300, epoch: 5 | loss: 0.2317258\n",
      "\tspeed: 0.6187s/iter; left time: 1218.1712s\n",
      "Epoch: 5 cost time: 234.31951141357422\n",
      "Epoch: 5, Steps: 378 | Train Loss: 0.2415011 Vali Loss: 0.4749190 Test Loss: 0.6246595\n",
      "Validation loss decreased (0.475765 --> 0.474919).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2470496\n",
      "\tspeed: 1.5461s/iter; left time: 2769.1122s\n",
      "\titers: 200, epoch: 6 | loss: 0.2375240\n",
      "\tspeed: 0.6180s/iter; left time: 1044.9666s\n",
      "\titers: 300, epoch: 6 | loss: 0.2177039\n",
      "\tspeed: 0.6175s/iter; left time: 982.4985s\n",
      "Epoch: 6 cost time: 234.02600765228271\n",
      "Epoch: 6, Steps: 378 | Train Loss: 0.2393767 Vali Loss: 0.4727746 Test Loss: 0.6218433\n",
      "Validation loss decreased (0.474919 --> 0.472775).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2286649\n",
      "\tspeed: 1.5475s/iter; left time: 2186.6196s\n",
      "\titers: 200, epoch: 7 | loss: 0.2555223\n",
      "\tspeed: 0.6199s/iter; left time: 813.8809s\n",
      "\titers: 300, epoch: 7 | loss: 0.2419802\n",
      "\tspeed: 0.6209s/iter; left time: 753.1333s\n",
      "Epoch: 7 cost time: 234.9201316833496\n",
      "Epoch: 7, Steps: 378 | Train Loss: 0.2382451 Vali Loss: 0.4724076 Test Loss: 0.6220728\n",
      "Validation loss decreased (0.472775 --> 0.472408).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2427372\n",
      "\tspeed: 1.5559s/iter; left time: 1610.3982s\n",
      "\titers: 200, epoch: 8 | loss: 0.2192655\n",
      "\tspeed: 0.6210s/iter; left time: 580.6058s\n",
      "\titers: 300, epoch: 8 | loss: 0.2400279\n",
      "\tspeed: 0.6219s/iter; left time: 519.2523s\n",
      "Epoch: 8 cost time: 235.52487111091614\n",
      "Epoch: 8, Steps: 378 | Train Loss: 0.2375721 Vali Loss: 0.4722835 Test Loss: 0.6222647\n",
      "Validation loss decreased (0.472408 --> 0.472284).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.2557503\n",
      "\tspeed: 1.5547s/iter; left time: 1021.4128s\n",
      "\titers: 200, epoch: 9 | loss: 0.2383726\n",
      "\tspeed: 0.6214s/iter; left time: 346.1294s\n",
      "\titers: 300, epoch: 9 | loss: 0.2382292\n",
      "\tspeed: 0.6213s/iter; left time: 283.9411s\n",
      "Epoch: 9 cost time: 235.4706962108612\n",
      "Epoch: 9, Steps: 378 | Train Loss: 0.2372652 Vali Loss: 0.4730500 Test Loss: 0.6224188\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.2559462\n",
      "\tspeed: 1.5322s/iter; left time: 427.4929s\n",
      "\titers: 200, epoch: 10 | loss: 0.2322389\n",
      "\tspeed: 0.6177s/iter; left time: 110.5659s\n",
      "\titers: 300, epoch: 10 | loss: 0.2391559\n",
      "\tspeed: 0.6175s/iter; left time: 48.7809s\n",
      "Epoch: 10 cost time: 234.37203979492188\n",
      "Epoch: 10, Steps: 378 | Train Loss: 0.2370779 Vali Loss: 0.4730487 Test Loss: 0.6225889\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast_traffic_missing015_96_96_TimesNet_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df512_expand2_dc4_fc3_ebtimeF_dtTrue_MissingTest_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 3413\n",
      "test shape: (3413, 96, 862) (3413, 96, 862)\n",
      "test shape: (3413, 96, 862) (3413, 96, 862)\n",
      "mse:0.6232136487960815, mae:0.3381824791431427, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./dataset/traffic/ \\\n",
    "  --data_path traffic_missing_015.csv \\\n",
    "  --model_id traffic_missing015_96_96 \\\n",
    "  --model TimesNet \\\n",
    "  --data custom \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 862 \\\n",
    "  --dec_in 862 \\\n",
    "  --c_out 862 \\\n",
    "  --d_model 512 \\\n",
    "  --d_ff 512 \\\n",
    "  --top_k 5 \\\n",
    "  --des 'MissingTest' \\\n",
    "  --itr 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CObJ6L8pea83"
   },
   "source": [
    "# missing rate = 20%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13494,
     "status": "ok",
     "timestamp": 1745487632555,
     "user": {
      "displayName": "Alice Jiang",
      "userId": "03912150214395170852"
     },
     "user_tz": -480
    },
    "id": "msaCsO1DByTI",
    "outputId": "e133fbdb-6626-4c71-defb-6fda727c372d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-32e694d7611b>:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n",
      "<ipython-input-13-32e694d7611b>:20: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "missing_rate = 0.2\n",
    "np.random.seed(42)\n",
    "\n",
    "original_file = './dataset/traffic/traffic.csv'\n",
    "missing_file = './dataset/traffic/traffic_missing_02.csv'\n",
    "\n",
    "df = pd.read_csv(original_file)\n",
    "\n",
    "cols = [col for col in df.columns if col != 'date']\n",
    "for col in cols:\n",
    "    n_missing = int(len(df) * missing_rate)\n",
    "    missing_indices = np.random.choice(df.index, n_missing, replace=False)\n",
    "    df.loc[missing_indices, col] = np.nan\n",
    "\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "df.to_csv(missing_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1046806,
     "status": "ok",
     "timestamp": 1744884441035,
     "user": {
      "displayName": "Alice Jiang",
      "userId": "03912150214395170852"
     },
     "user_tz": -480
    },
    "id": "O7Yt-Gc0C8a1",
    "outputId": "79050d73-0ccd-44ea-aad6-38390dd0f51f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Args in experiment:\n",
      "\u001b[1mBasic Config\u001b[0m\n",
      "  Task Name:          long_term_forecast  Is Training:        1                   \n",
      "  Model ID:           traffic_missing02_96_96Model:              TimesNet            \n",
      "\n",
      "\u001b[1mData Loader\u001b[0m\n",
      "  Data:               custom              Root Path:          ./dataset/traffic/  \n",
      "  Data Path:          traffic_missing_02.csvFeatures:           M                   \n",
      "  Target:             OT                  Freq:               h                   \n",
      "  Checkpoints:        ./checkpoints/      \n",
      "\n",
      "\u001b[1mForecasting Task\u001b[0m\n",
      "  Seq Len:            96                  Label Len:          48                  \n",
      "  Pred Len:           96                  Seasonal Patterns:  Monthly             \n",
      "  Inverse:            0                   \n",
      "\n",
      "\u001b[1mModel Parameters\u001b[0m\n",
      "  Top k:              5                   Num Kernels:        6                   \n",
      "  Enc In:             862                 Dec In:             862                 \n",
      "  C Out:              862                 d model:            512                 \n",
      "  n heads:            8                   e layers:           2                   \n",
      "  d layers:           1                   d FF:               512                 \n",
      "  Moving Avg:         25                  Factor:             3                   \n",
      "  Distil:             1                   Dropout:            0.1                 \n",
      "  Embed:              timeF               Activation:         gelu                \n",
      "\n",
      "\u001b[1mRun Parameters\u001b[0m\n",
      "  Num Workers:        10                  Itr:                1                   \n",
      "  Train Epochs:       10                  Batch Size:         32                  \n",
      "  Patience:           3                   Learning Rate:      0.0001              \n",
      "  Des:                MissingTest         Loss:               MSE                 \n",
      "  Lradj:              type1               Use Amp:            0                   \n",
      "\n",
      "\u001b[1mGPU\u001b[0m\n",
      "  Use GPU:            1                   GPU:                0                   \n",
      "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
      "\n",
      "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
      "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
      "\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_traffic_missing02_96_96_TimesNet_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df512_expand2_dc4_fc3_ebtimeF_dtTrue_MissingTest_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 12089\n",
      "val 1661\n",
      "test 3413\n",
      "\titers: 100, epoch: 1 | loss: 0.4480336\n",
      "\tspeed: 0.6219s/iter; left time: 2289.3755s\n",
      "\titers: 200, epoch: 1 | loss: 0.3222632\n",
      "\tspeed: 0.6118s/iter; left time: 2191.0068s\n",
      "\titers: 300, epoch: 1 | loss: 0.2882554\n",
      "\tspeed: 0.6159s/iter; left time: 2143.9233s\n",
      "Epoch: 1 cost time: 233.5418894290924\n",
      "Epoch: 1, Steps: 378 | Train Loss: 0.3945266 Vali Loss: 0.5131980 Test Loss: 0.6623064\n",
      "Validation loss decreased (inf --> 0.513198).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2658362\n",
      "\tspeed: 1.5285s/iter; left time: 5048.5754s\n",
      "\titers: 200, epoch: 2 | loss: 0.2774094\n",
      "\tspeed: 0.6199s/iter; left time: 1985.6744s\n",
      "\titers: 300, epoch: 2 | loss: 0.2704133\n",
      "\tspeed: 0.6203s/iter; left time: 1924.7422s\n",
      "Epoch: 2 cost time: 234.9904191493988\n",
      "Epoch: 2, Steps: 378 | Train Loss: 0.2823843 Vali Loss: 0.4955485 Test Loss: 0.6425611\n",
      "Validation loss decreased (0.513198 --> 0.495549).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2743459\n",
      "\tspeed: 1.5479s/iter; left time: 4527.5465s\n",
      "\titers: 200, epoch: 3 | loss: 0.2769334\n",
      "\tspeed: 0.6190s/iter; left time: 1748.6230s\n",
      "\titers: 300, epoch: 3 | loss: 0.2664114\n",
      "\tspeed: 0.6189s/iter; left time: 1686.6330s\n",
      "Epoch: 3 cost time: 234.4290521144867\n",
      "Epoch: 3, Steps: 378 | Train Loss: 0.2660329 Vali Loss: 0.4969324 Test Loss: 0.6468204\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2660542\n",
      "\tspeed: 1.5164s/iter; left time: 3862.2257s\n",
      "\titers: 200, epoch: 4 | loss: 0.2544121\n",
      "\tspeed: 0.6164s/iter; left time: 1508.3889s\n",
      "\titers: 300, epoch: 4 | loss: 0.2781449\n",
      "\tspeed: 0.6166s/iter; left time: 1447.1525s\n",
      "Epoch: 4 cost time: 233.50362467765808\n",
      "Epoch: 4, Steps: 378 | Train Loss: 0.2590388 Vali Loss: 0.4871347 Test Loss: 0.6371955\n",
      "Validation loss decreased (0.495549 --> 0.487135).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2646289\n",
      "\tspeed: 1.5384s/iter; left time: 3336.7114s\n",
      "\titers: 200, epoch: 5 | loss: 0.2511423\n",
      "\tspeed: 0.6157s/iter; left time: 1273.9732s\n",
      "\titers: 300, epoch: 5 | loss: 0.2459421\n",
      "\tspeed: 0.6166s/iter; left time: 1214.1116s\n",
      "Epoch: 5 cost time: 233.38209652900696\n",
      "Epoch: 5, Steps: 378 | Train Loss: 0.2552316 Vali Loss: 0.4870698 Test Loss: 0.6387633\n",
      "Validation loss decreased (0.487135 --> 0.487070).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2593840\n",
      "\tspeed: 1.5412s/iter; left time: 2760.2658s\n",
      "\titers: 200, epoch: 6 | loss: 0.2518117\n",
      "\tspeed: 0.6178s/iter; left time: 1044.6904s\n",
      "\titers: 300, epoch: 6 | loss: 0.2309966\n",
      "\tspeed: 0.6184s/iter; left time: 983.8460s\n",
      "Epoch: 6 cost time: 233.97399616241455\n",
      "Epoch: 6, Steps: 378 | Train Loss: 0.2531895 Vali Loss: 0.4844904 Test Loss: 0.6354229\n",
      "Validation loss decreased (0.487070 --> 0.484490).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2404213\n",
      "\tspeed: 1.5476s/iter; left time: 2186.7561s\n",
      "\titers: 200, epoch: 7 | loss: 0.2722294\n",
      "\tspeed: 0.6193s/iter; left time: 813.2007s\n",
      "\titers: 300, epoch: 7 | loss: 0.2560329\n",
      "\tspeed: 0.6191s/iter; left time: 750.9655s\n",
      "Epoch: 7 cost time: 234.64016675949097\n",
      "Epoch: 7, Steps: 378 | Train Loss: 0.2520790 Vali Loss: 0.4849434 Test Loss: 0.6366680\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2567492\n",
      "\tspeed: 1.5242s/iter; left time: 1577.5411s\n",
      "\titers: 200, epoch: 8 | loss: 0.2327193\n",
      "\tspeed: 0.6190s/iter; left time: 578.7310s\n",
      "\titers: 300, epoch: 8 | loss: 0.2530051\n",
      "\tspeed: 0.6191s/iter; left time: 516.9798s\n",
      "Epoch: 8 cost time: 234.66515517234802\n",
      "Epoch: 8, Steps: 378 | Train Loss: 0.2514242 Vali Loss: 0.4842992 Test Loss: 0.6360437\n",
      "Validation loss decreased (0.484490 --> 0.484299).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.2705557\n",
      "\tspeed: 1.5472s/iter; left time: 1016.5429s\n",
      "\titers: 200, epoch: 9 | loss: 0.2526918\n",
      "\tspeed: 0.6187s/iter; left time: 344.5915s\n",
      "\titers: 300, epoch: 9 | loss: 0.2514172\n",
      "\tspeed: 0.6189s/iter; left time: 282.8199s\n",
      "Epoch: 9 cost time: 234.46936082839966\n",
      "Epoch: 9, Steps: 378 | Train Loss: 0.2511076 Vali Loss: 0.4849071 Test Loss: 0.6363997\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.2711676\n",
      "\tspeed: 1.5234s/iter; left time: 425.0355s\n",
      "\titers: 200, epoch: 10 | loss: 0.2466300\n",
      "\tspeed: 0.6182s/iter; left time: 110.6564s\n",
      "\titers: 300, epoch: 10 | loss: 0.2525422\n",
      "\tspeed: 0.6184s/iter; left time: 48.8510s\n",
      "Epoch: 10 cost time: 234.3626048564911\n",
      "Epoch: 10, Steps: 378 | Train Loss: 0.2509256 Vali Loss: 0.4848611 Test Loss: 0.6365168\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : long_term_forecast_traffic_missing02_96_96_TimesNet_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df512_expand2_dc4_fc3_ebtimeF_dtTrue_MissingTest_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 3413\n",
      "test shape: (3413, 96, 862) (3413, 96, 862)\n",
      "test shape: (3413, 96, 862) (3413, 96, 862)\n",
      "mse:0.6370114684104919, mae:0.3480421006679535, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./dataset/traffic/ \\\n",
    "  --data_path traffic_missing_02.csv \\\n",
    "  --model_id traffic_missing02_96_96 \\\n",
    "  --model TimesNet \\\n",
    "  --data custom \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 862 \\\n",
    "  --dec_in 862 \\\n",
    "  --c_out 862 \\\n",
    "  --d_model 512 \\\n",
    "  --d_ff 512 \\\n",
    "  --top_k 5 \\\n",
    "  --des 'MissingTest' \\\n",
    "  --itr 1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPKshWHt/GXbD9LjslJZVer",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
