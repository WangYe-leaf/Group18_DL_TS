{"cells":[{"cell_type":"code","metadata":{"source_hash":"1acff9c4","execution_start":1744898452880,"execution_millis":89,"execution_context_id":"665d62ca-4523-4fe9-aa11-a62d7fb2a3ed","cell_id":"43e89bff12694d099f9d9209b4566bf8","deepnote_cell_type":"code"},"source":"%cd Time-Series-Library\n!pwd","block_group":"43e89bff12694d099f9d9209b4566bf8","execution_count":1,"outputs":[{"name":"stdout","text":"/datasets/_deepnote_work/Time-Series-Library\n/datasets/_deepnote_work/Time-Series-Library\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/18abd5e1-fb14-406e-8284-5f47ab39f646","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"3fbcaa96","execution_start":1744898560000,"execution_millis":525,"execution_context_id":"665d62ca-4523-4fe9-aa11-a62d7fb2a3ed","cell_id":"ec8fd7c83048478d979980457c9d4513","deepnote_cell_type":"code"},"source":"import pandas as pd\n\n# 读取原始 weather.csv 文件（请根据你的真实路径修改）\ndf = pd.read_csv('./dataset/Weather/weather.csv')\nprint(\"原始数据行数：\", len(df))\n","block_group":"966428be102644e6aa856305c870ba9f","execution_count":4,"outputs":[{"name":"stdout","text":"原始数据行数： 52696\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/da82b50f-4a1c-4900-9593-eef0bf2e1dda","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"e24e3220","execution_start":1744898572800,"execution_millis":1337,"execution_context_id":"665d62ca-4523-4fe9-aa11-a62d7fb2a3ed","cell_id":"93b6595d99044f0594d5f7df2a908db2","deepnote_cell_type":"code"},"source":"# 裁剪为 75%、50%、25% 的前部数据\ndf_75 = df.iloc[:int(len(df)*0.75)]\ndf_50 = df.iloc[:int(len(df)*0.50)]\ndf_25 = df.iloc[:int(len(df)*0.25)]\n\n# 保存为新的文件（你也可以改路径，比如放入 Weather 文件夹）\ndf_75.to_csv('./dataset/Weather/weather_75.csv', index=False)\ndf_50.to_csv('./dataset/Weather/weather_50.csv', index=False)\ndf_25.to_csv('./dataset/Weather/weather_25.csv', index=False)","block_group":"0b48f72315e141608bb1c538a9e32a02","execution_count":7,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"5d25aadd","execution_start":1744898866660,"execution_millis":1339,"execution_context_id":"665d62ca-4523-4fe9-aa11-a62d7fb2a3ed","cell_id":"247d31791e91405fb1040c72a76b52f3","deepnote_cell_type":"code"},"source":"# 一级目录：Robustness 下面建 DataVolume 子目录\n!mkdir -p result/Robustness/DataVolume/PatchTST_weather_75\n!mkdir -p result/Robustness/DataVolume/PatchTST_weather_50\n!mkdir -p result/Robustness/DataVolume/PatchTST_weather_25","block_group":"74255795cab245a89158a817fa2da03a","execution_count":10,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"3a3d36ca","execution_start":1744899400140,"execution_millis":3373060,"execution_context_id":"665d62ca-4523-4fe9-aa11-a62d7fb2a3ed","cell_id":"f4fd96ca42044bdba2f6d3d4a9d7948b","deepnote_cell_type":"code"},"source":"# ===== Weather 25% =====\n!mkdir -p result/Robustness/DataVolume/PatchTST_weather_25\n\n!python run.py \\\n--is_training 1 \\\n--task_name long_term_forecast \\\n--model_id PatchTST_weather_25 \\\n--model PatchTST \\\n--data custom \\\n--root_path ./dataset/Weather \\\n--data_path weather_25.csv \\\n--features M \\\n--seq_len 336 \\\n--pred_len 96 \\\n--e_layers 2 \\\n--d_layers 1 \\\n--enc_in 21 \\\n--learning_rate 0.001 \\\n--train_epochs 50 \\\n--batch_size 32 \\\n--patience 10 \\\n--checkpoints ./result/Robustness/DataVolume/PatchTST_weather_25 \\\n--des robustness_datavolume \\\n2>&1 | tee result/Robustness/DataVolume/PatchTST_weather_25/train_log.txt\n","block_group":"63af4c793470465b8c00a693075c82fd","execution_count":13,"outputs":[{"name":"stdout","text":"Using GPU\nArgs in experiment:\n\u001b[1mBasic Config\u001b[0m\n  Task Name:          long_term_forecast  Is Training:        1                   \n  Model ID:           PatchTST_weather_25 Model:              PatchTST            \n\n\u001b[1mData Loader\u001b[0m\n  Data:               custom              Root Path:          ./dataset/Weather   \n  Data Path:          weather_25.csv      Features:           M                   \n  Target:             OT                  Freq:               h                   \n  Checkpoints:        ./result/Robustness/DataVolume/PatchTST_weather_25\n\n\u001b[1mForecasting Task\u001b[0m\n  Seq Len:            336                 Label Len:          48                  \n  Pred Len:           96                  Seasonal Patterns:  Monthly             \n  Inverse:            0                   \n\n\u001b[1mModel Parameters\u001b[0m\n  Top k:              5                   Num Kernels:        6                   \n  Enc In:             21                  Dec In:             7                   \n  C Out:              7                   d model:            512                 \n  n heads:            8                   e layers:           2                   \n  d layers:           1                   d FF:               2048                \n  Moving Avg:         25                  Factor:             1                   \n  Distil:             1                   Dropout:            0.1                 \n  Embed:              timeF               Activation:         gelu                \n\n\u001b[1mRun Parameters\u001b[0m\n  Num Workers:        10                  Itr:                1                   \n  Train Epochs:       50                  Batch Size:         32                  \n  Patience:           10                  Learning Rate:      0.001               \n  Des:                robustness_datavolumeLoss:               MSE                 \n  Lradj:              type1               Use Amp:            0                   \n\n\u001b[1mGPU\u001b[0m\n  Use GPU:            1                   GPU:                0                   \n  Use Multi GPU:      0                   Devices:            0,1,2,3             \n\n\u001b[1mDe-stationary Projector Params\u001b[0m\n  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n\nUse GPU: cuda:0\n>>>>>>>start training : long_term_forecast_PatchTST_weather_25_PatchTST_custom_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_robustness_datavolume_0>>>>>>>>>>>>>>>>>>>>>>>>>>\ntrain 8790\nval 1224\ntest 2539\n\titers: 100, epoch: 1 | loss: 0.8749892\n\tspeed: 0.5927s/iter; left time: 8091.0484s\n\titers: 200, epoch: 1 | loss: 0.9717590\n\tspeed: 0.5769s/iter; left time: 7817.7348s\nEpoch: 1 cost time: 154.3653688430786\nEpoch: 1, Steps: 275 | Train Loss: 1.1389674 Vali Loss: 1.1671171 Test Loss: 1.5075022\nValidation loss decreased (inf --> 1.167117).  Saving model ...\nUpdating learning rate to 0.001\n\titers: 100, epoch: 2 | loss: 1.0404195\n\tspeed: 1.0288s/iter; left time: 13761.7652s\n\titers: 200, epoch: 2 | loss: 0.8761104\n\tspeed: 0.5868s/iter; left time: 7791.0124s\nEpoch: 2 cost time: 153.9908697605133\nEpoch: 2, Steps: 275 | Train Loss: 0.9546941 Vali Loss: 1.0299876 Test Loss: 1.3508872\nValidation loss decreased (1.167117 --> 1.029988).  Saving model ...\nUpdating learning rate to 0.0005\n\titers: 100, epoch: 3 | loss: 0.7179258\n\tspeed: 1.1763s/iter; left time: 15410.4229s\n\titers: 200, epoch: 3 | loss: 0.9456649\n\tspeed: 0.5863s/iter; left time: 7622.0210s\nEpoch: 3 cost time: 161.06591248512268\nEpoch: 3, Steps: 275 | Train Loss: 0.7304531 Vali Loss: 0.9480400 Test Loss: 1.3106215\nValidation loss decreased (1.029988 --> 0.948040).  Saving model ...\nUpdating learning rate to 0.00025\n\titers: 100, epoch: 4 | loss: 0.5190140\n\tspeed: 1.1796s/iter; left time: 15129.1765s\n\titers: 200, epoch: 4 | loss: 0.7910885\n\tspeed: 0.5869s/iter; left time: 7469.2953s\nEpoch: 4 cost time: 161.18986749649048\nEpoch: 4, Steps: 275 | Train Loss: 0.6600597 Vali Loss: 0.9147433 Test Loss: 1.0092379\nValidation loss decreased (0.948040 --> 0.914743).  Saving model ...\nUpdating learning rate to 0.000125\n\titers: 100, epoch: 5 | loss: 0.7210589\n\tspeed: 1.1794s/iter; left time: 14802.7817s\n\titers: 200, epoch: 5 | loss: 0.6179059\n\tspeed: 0.5872s/iter; left time: 7311.5497s\nEpoch: 5 cost time: 161.27722191810608\nEpoch: 5, Steps: 275 | Train Loss: 0.6249137 Vali Loss: 0.8610618 Test Loss: 0.9717695\nValidation loss decreased (0.914743 --> 0.861062).  Saving model ...\nUpdating learning rate to 6.25e-05\n\titers: 100, epoch: 6 | loss: 0.5673922\n\tspeed: 1.1558s/iter; left time: 14188.7292s\n\titers: 200, epoch: 6 | loss: 0.4612661\n\tspeed: 0.4924s/iter; left time: 5995.8840s\nEpoch: 6 cost time: 142.70639061927795\nEpoch: 6, Steps: 275 | Train Loss: 0.6070303 Vali Loss: 0.8637828 Test Loss: 0.9632475\nEarlyStopping counter: 1 out of 10\nUpdating learning rate to 3.125e-05\n\titers: 100, epoch: 7 | loss: 0.8632525\n\tspeed: 1.1039s/iter; left time: 13247.3862s\n\titers: 200, epoch: 7 | loss: 0.4980157\n\tspeed: 0.5829s/iter; left time: 6937.0859s\nEpoch: 7 cost time: 160.09350037574768\nEpoch: 7, Steps: 275 | Train Loss: 0.5978514 Vali Loss: 0.8489107 Test Loss: 0.9530619\nValidation loss decreased (0.861062 --> 0.848911).  Saving model ...\nUpdating learning rate to 1.5625e-05\n\titers: 100, epoch: 8 | loss: 0.4173800\n\tspeed: 1.1763s/iter; left time: 13792.8780s\n\titers: 200, epoch: 8 | loss: 0.5428421\n\tspeed: 0.5837s/iter; left time: 6786.1574s\nEpoch: 8 cost time: 160.60452318191528\nEpoch: 8, Steps: 275 | Train Loss: 0.5925396 Vali Loss: 0.8329490 Test Loss: 0.9493240\nValidation loss decreased (0.848911 --> 0.832949).  Saving model ...\nUpdating learning rate to 7.8125e-06\n\titers: 100, epoch: 9 | loss: 0.6080604\n\tspeed: 1.1784s/iter; left time: 13494.0910s\n\titers: 200, epoch: 9 | loss: 0.5672819\n\tspeed: 0.5849s/iter; left time: 6639.2905s\nEpoch: 9 cost time: 160.49688267707825\nEpoch: 9, Steps: 275 | Train Loss: 0.5895897 Vali Loss: 0.8251222 Test Loss: 0.9396728\nValidation loss decreased (0.832949 --> 0.825122).  Saving model ...\nUpdating learning rate to 3.90625e-06\n\titers: 100, epoch: 10 | loss: 0.5041637\n\tspeed: 1.1805s/iter; left time: 13192.8232s\n\titers: 200, epoch: 10 | loss: 0.4775415\n\tspeed: 0.5836s/iter; left time: 6464.1455s\nEpoch: 10 cost time: 159.49009490013123\nEpoch: 10, Steps: 275 | Train Loss: 0.5885980 Vali Loss: 0.8339956 Test Loss: 0.9362429\nEarlyStopping counter: 1 out of 10\nUpdating learning rate to 1.953125e-06\n\titers: 100, epoch: 11 | loss: 0.7188565\n\tspeed: 1.0482s/iter; left time: 11426.5390s\n\titers: 200, epoch: 11 | loss: 0.6090978\n\tspeed: 0.5286s/iter; left time: 5709.6390s\nEpoch: 11 cost time: 146.2440960407257\nEpoch: 11, Steps: 275 | Train Loss: 0.5878248 Vali Loss: 0.8341205 Test Loss: 0.9362671\nEarlyStopping counter: 2 out of 10\nUpdating learning rate to 9.765625e-07\n\titers: 100, epoch: 12 | loss: 1.0150942\n\tspeed: 1.1692s/iter; left time: 12423.8179s\n\titers: 200, epoch: 12 | loss: 0.5099383\n\tspeed: 0.5837s/iter; left time: 6143.6517s\nEpoch: 12 cost time: 160.6093008518219\nEpoch: 12, Steps: 275 | Train Loss: 0.5877219 Vali Loss: 0.8319774 Test Loss: 0.9344177\nEarlyStopping counter: 3 out of 10\nUpdating learning rate to 4.8828125e-07\n\titers: 100, epoch: 13 | loss: 0.4001393\n\tspeed: 1.1690s/iter; left time: 12099.8606s\n\titers: 200, epoch: 13 | loss: 0.5915443\n\tspeed: 0.5822s/iter; left time: 5968.2877s\nEpoch: 13 cost time: 160.44150400161743\nEpoch: 13, Steps: 275 | Train Loss: 0.5869281 Vali Loss: 0.8285808 Test Loss: 0.9337371\nEarlyStopping counter: 4 out of 10\nUpdating learning rate to 2.44140625e-07\n\titers: 100, epoch: 14 | loss: 0.7829745\n\tspeed: 1.1652s/iter; left time: 11740.7228s\n\titers: 200, epoch: 14 | loss: 0.6712282\n\tspeed: 0.5846s/iter; left time: 5831.6820s\nEpoch: 14 cost time: 160.6627848148346\nEpoch: 14, Steps: 275 | Train Loss: 0.5861583 Vali Loss: 0.8386520 Test Loss: 0.9339579\nEarlyStopping counter: 5 out of 10\nUpdating learning rate to 1.220703125e-07\n\titers: 100, epoch: 15 | loss: 0.3420789\n\tspeed: 1.1729s/iter; left time: 11495.1883s\n\titers: 200, epoch: 15 | loss: 0.7605188\n\tspeed: 0.5566s/iter; left time: 5399.2729s\nEpoch: 15 cost time: 151.28388214111328\nEpoch: 15, Steps: 275 | Train Loss: 0.5872327 Vali Loss: 0.8326024 Test Loss: 0.9338156\nEarlyStopping counter: 6 out of 10\nUpdating learning rate to 6.103515625e-08\n\titers: 100, epoch: 16 | loss: 0.5124370\n\tspeed: 1.0970s/iter; left time: 10450.0632s\n\titers: 200, epoch: 16 | loss: 0.5493950\n\tspeed: 0.6227s/iter; left time: 5869.2022s\nEpoch: 16 cost time: 165.74345231056213\nEpoch: 16, Steps: 275 | Train Loss: 0.5865271 Vali Loss: 0.8379000 Test Loss: 0.9347884\nEarlyStopping counter: 7 out of 10\nUpdating learning rate to 3.0517578125e-08\n\titers: 100, epoch: 17 | loss: 1.1270556\n\tspeed: 1.3823s/iter; left time: 12787.5602s\n\titers: 200, epoch: 17 | loss: 0.4322211\n\tspeed: 0.8054s/iter; left time: 7370.0104s\nEpoch: 17 cost time: 218.93546223640442\nEpoch: 17, Steps: 275 | Train Loss: 0.5868367 Vali Loss: 0.8390203 Test Loss: 0.9347116\nEarlyStopping counter: 8 out of 10\nUpdating learning rate to 1.52587890625e-08\n\titers: 100, epoch: 18 | loss: 0.9136932\n\tspeed: 1.3208s/iter; left time: 11855.2518s\n\titers: 200, epoch: 18 | loss: 0.5926990\n\tspeed: 0.5869s/iter; left time: 5209.7134s\nEpoch: 18 cost time: 161.18086957931519\nEpoch: 18, Steps: 275 | Train Loss: 0.5862856 Vali Loss: 0.8395298 Test Loss: 0.9349009\nEarlyStopping counter: 9 out of 10\nUpdating learning rate to 7.62939453125e-09\n\titers: 100, epoch: 19 | loss: 0.8729705\n\tspeed: 1.1716s/iter; left time: 10194.0828s\n\titers: 200, epoch: 19 | loss: 1.0335822\n\tspeed: 0.5868s/iter; left time: 5047.2039s\nEpoch: 19 cost time: 161.23959016799927\nEpoch: 19, Steps: 275 | Train Loss: 0.5867055 Vali Loss: 0.8388162 Test Loss: 0.9343815\nEarlyStopping counter: 10 out of 10\nEarly stopping\n>>>>>>>testing : long_term_forecast_PatchTST_weather_25_PatchTST_custom_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_robustness_datavolume_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\ntest 2539\ntest shape: (2539, 96, 21) (2539, 96, 21)\ntest shape: (2539, 96, 21) (2539, 96, 21)\nmse:0.940398633480072, mae:0.5965114831924438, dtw:Not calculated\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/6c412b5f-7741-465d-aa69-6e9b546b0add","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":"72b31c55","execution_start":1744903211490,"execution_millis":9081792,"execution_context_id":"665d62ca-4523-4fe9-aa11-a62d7fb2a3ed","cell_id":"a84ff643753e49c191a838ded267c877","deepnote_cell_type":"code"},"source":"# ===== Weather 50% =====\n!mkdir -p result/Robustness/DataVolume/PatchTST_weather_50\n\n!python run.py \\\n--is_training 1 \\\n--task_name long_term_forecast \\\n--model_id PatchTST_weather_50 \\\n--model PatchTST \\\n--data custom \\\n--root_path ./dataset/Weather \\\n--data_path weather_50.csv \\\n--features M \\\n--seq_len 336 \\\n--pred_len 96 \\\n--e_layers 2 \\\n--d_layers 1 \\\n--enc_in 21 \\\n--learning_rate 0.001 \\\n--train_epochs 50 \\\n--batch_size 32 \\\n--patience 10 \\\n--checkpoints ./result/Robustness/DataVolume/PatchTST_weather_50 \\\n--des robustness_datavolume \\\n2>&1 | tee result/Robustness/DataVolume/PatchTST_weather_50/train_log.txt","block_group":"f3a00f9d932a4eaba1d9a3c5f82ec731","execution_count":16,"outputs":[{"name":"stdout","text":"Using GPU\nArgs in experiment:\n\u001b[1mBasic Config\u001b[0m\n  Task Name:          long_term_forecast  Is Training:        1                   \n  Model ID:           PatchTST_weather_50 Model:              PatchTST            \n\n\u001b[1mData Loader\u001b[0m\n  Data:               custom              Root Path:          ./dataset/Weather   \n  Data Path:          weather_50.csv      Features:           M                   \n  Target:             OT                  Freq:               h                   \n  Checkpoints:        ./result/Robustness/DataVolume/PatchTST_weather_50\n\n\u001b[1mForecasting Task\u001b[0m\n  Seq Len:            336                 Label Len:          48                  \n  Pred Len:           96                  Seasonal Patterns:  Monthly             \n  Inverse:            0                   \n\n\u001b[1mModel Parameters\u001b[0m\n  Top k:              5                   Num Kernels:        6                   \n  Enc In:             21                  Dec In:             7                   \n  C Out:              7                   d model:            512                 \n  n heads:            8                   e layers:           2                   \n  d layers:           1                   d FF:               2048                \n  Moving Avg:         25                  Factor:             1                   \n  Distil:             1                   Dropout:            0.1                 \n  Embed:              timeF               Activation:         gelu                \n\n\u001b[1mRun Parameters\u001b[0m\n  Num Workers:        10                  Itr:                1                   \n  Train Epochs:       50                  Batch Size:         32                  \n  Patience:           10                  Learning Rate:      0.001               \n  Des:                robustness_datavolumeLoss:               MSE                 \n  Lradj:              type1               Use Amp:            0                   \n\n\u001b[1mGPU\u001b[0m\n  Use GPU:            1                   GPU:                0                   \n  Use Multi GPU:      0                   Devices:            0,1,2,3             \n\n\u001b[1mDe-stationary Projector Params\u001b[0m\n  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n\nUse GPU: cuda:0\n>>>>>>>start training : long_term_forecast_PatchTST_weather_50_PatchTST_custom_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_robustness_datavolume_0>>>>>>>>>>>>>>>>>>>>>>>>>>\ntrain 18012\nval 2541\ntest 5174\n\titers: 100, epoch: 1 | loss: 0.6545856\n\tspeed: 0.7556s/iter; left time: 21195.9062s\n\titers: 200, epoch: 1 | loss: 0.7250434\n\tspeed: 0.8221s/iter; left time: 22979.7662s\n\titers: 300, epoch: 1 | loss: 0.7735066\n\tspeed: 0.7490s/iter; left time: 20859.6015s\n\titers: 400, epoch: 1 | loss: 0.7050958\n\tspeed: 0.7867s/iter; left time: 21831.9082s\n\titers: 500, epoch: 1 | loss: 1.6082129\n\tspeed: 0.8260s/iter; left time: 22839.3399s\nEpoch: 1 cost time: 445.66915011405945\nEpoch: 1, Steps: 563 | Train Loss: 0.9605976 Vali Loss: 1.2341728 Test Loss: 1.7395351\nValidation loss decreased (inf --> 1.234173).  Saving model ...\nUpdating learning rate to 0.001\n\titers: 100, epoch: 2 | loss: 0.7697339\n\tspeed: 1.7578s/iter; left time: 48319.6018s\n\titers: 200, epoch: 2 | loss: 0.7405505\n\tspeed: 0.7379s/iter; left time: 20210.5783s\n\titers: 300, epoch: 2 | loss: 0.6342373\n\tspeed: 0.8212s/iter; left time: 22408.3628s\n\titers: 400, epoch: 2 | loss: 0.6272105\n\tspeed: 0.8234s/iter; left time: 22386.2981s\n\titers: 500, epoch: 2 | loss: 0.5647432\n\tspeed: 0.8216s/iter; left time: 22255.6560s\nEpoch: 2 cost time: 454.66275691986084\nEpoch: 2, Steps: 563 | Train Loss: 0.8404940 Vali Loss: 0.9317306 Test Loss: 1.4151180\nValidation loss decreased (1.234173 --> 0.931731).  Saving model ...\nUpdating learning rate to 0.0005\n\titers: 100, epoch: 3 | loss: 1.0001528\n\tspeed: 1.7363s/iter; left time: 46749.2051s\n\titers: 200, epoch: 3 | loss: 0.4884609\n\tspeed: 0.5869s/iter; left time: 15744.6090s\n\titers: 300, epoch: 3 | loss: 0.4577054\n\tspeed: 0.6839s/iter; left time: 18277.8697s\n\titers: 400, epoch: 3 | loss: 0.4928373\n\tspeed: 0.7699s/iter; left time: 20499.1300s\n\titers: 500, epoch: 3 | loss: 0.5731257\n\tspeed: 0.7749s/iter; left time: 20553.6790s\nEpoch: 3 cost time: 412.2667725086212\nEpoch: 3, Steps: 563 | Train Loss: 0.6005622 Vali Loss: 0.8093078 Test Loss: 1.2995735\nValidation loss decreased (0.931731 --> 0.809308).  Saving model ...\nUpdating learning rate to 0.00025\n\titers: 100, epoch: 4 | loss: 0.5429972\n\tspeed: 1.7551s/iter; left time: 46267.8514s\n\titers: 200, epoch: 4 | loss: 1.1337664\n\tspeed: 0.8259s/iter; left time: 21689.1265s\n\titers: 300, epoch: 4 | loss: 0.4557115\n\tspeed: 0.7309s/iter; left time: 19121.2597s\n\titers: 400, epoch: 4 | loss: 0.5437620\n\tspeed: 0.8255s/iter; left time: 21514.1156s\n\titers: 500, epoch: 4 | loss: 0.4355681\n\tspeed: 0.8224s/iter; left time: 21350.3142s\nEpoch: 4 cost time: 454.6304221153259\nEpoch: 4, Steps: 563 | Train Loss: 0.5677569 Vali Loss: 0.8049989 Test Loss: 1.3045553\nValidation loss decreased (0.809308 --> 0.804999).  Saving model ...\nUpdating learning rate to 0.000125\n\titers: 100, epoch: 5 | loss: 0.4485613\n\tspeed: 1.7568s/iter; left time: 45322.4116s\n\titers: 200, epoch: 5 | loss: 0.3631772\n\tspeed: 0.7300s/iter; left time: 18759.9751s\n\titers: 300, epoch: 5 | loss: 0.4024073\n\tspeed: 0.8224s/iter; left time: 21053.7073s\n\titers: 400, epoch: 5 | loss: 0.5690773\n\tspeed: 0.8187s/iter; left time: 20875.0703s\n\titers: 500, epoch: 5 | loss: 0.4898765\n\tspeed: 0.8113s/iter; left time: 20607.3766s\nEpoch: 5 cost time: 448.521381855011\nEpoch: 5, Steps: 563 | Train Loss: 0.5542699 Vali Loss: 0.8072747 Test Loss: 1.2828090\nEarlyStopping counter: 1 out of 10\nUpdating learning rate to 6.25e-05\n\titers: 100, epoch: 6 | loss: 0.4137219\n\tspeed: 1.5491s/iter; left time: 39092.5378s\n\titers: 200, epoch: 6 | loss: 0.8948799\n\tspeed: 0.5868s/iter; left time: 14750.2113s\n\titers: 300, epoch: 6 | loss: 0.6088511\n\tspeed: 0.5865s/iter; left time: 14682.3676s\n\titers: 400, epoch: 6 | loss: 0.5271807\n\tspeed: 0.5866s/iter; left time: 14627.2558s\n\titers: 500, epoch: 6 | loss: 0.7150609\n\tspeed: 0.5867s/iter; left time: 14571.5596s\nEpoch: 6 cost time: 338.26739501953125\nEpoch: 6, Steps: 563 | Train Loss: 0.5464341 Vali Loss: 0.7814136 Test Loss: 1.2754452\nValidation loss decreased (0.804999 --> 0.781414).  Saving model ...\nUpdating learning rate to 3.125e-05\n\titers: 100, epoch: 7 | loss: 0.9604007\n\tspeed: 1.2805s/iter; left time: 31593.1546s\n\titers: 200, epoch: 7 | loss: 0.5167331\n\tspeed: 0.5868s/iter; left time: 14419.5626s\n\titers: 300, epoch: 7 | loss: 0.4061322\n\tspeed: 0.5865s/iter; left time: 14354.4469s\n\titers: 400, epoch: 7 | loss: 0.3778724\n\tspeed: 0.5849s/iter; left time: 14255.1714s\n\titers: 500, epoch: 7 | loss: 0.9622021\n\tspeed: 0.5812s/iter; left time: 14107.3736s\nEpoch: 7 cost time: 330.45003271102905\nEpoch: 7, Steps: 563 | Train Loss: 0.5416027 Vali Loss: 0.7751545 Test Loss: 1.2644562\nValidation loss decreased (0.781414 --> 0.775155).  Saving model ...\nUpdating learning rate to 1.5625e-05\n\titers: 100, epoch: 8 | loss: 0.9744424\n\tspeed: 1.2451s/iter; left time: 30019.0636s\n\titers: 200, epoch: 8 | loss: 0.4443566\n\tspeed: 0.5072s/iter; left time: 12176.7901s\n\titers: 300, epoch: 8 | loss: 0.5355450\n\tspeed: 0.5846s/iter; left time: 13976.8987s\n\titers: 400, epoch: 8 | loss: 0.4563282\n\tspeed: 0.5870s/iter; left time: 13977.3450s\n\titers: 500, epoch: 8 | loss: 0.4831293\n\tspeed: 0.5876s/iter; left time: 13932.1786s\nEpoch: 8 cost time: 312.4062476158142\nEpoch: 8, Steps: 563 | Train Loss: 0.5392165 Vali Loss: 0.7726912 Test Loss: 1.2646335\nValidation loss decreased (0.775155 --> 0.772691).  Saving model ...\nUpdating learning rate to 7.8125e-06\n\titers: 100, epoch: 9 | loss: 0.5208239\n\tspeed: 1.2601s/iter; left time: 29670.9435s\n\titers: 200, epoch: 9 | loss: 0.3566069\n\tspeed: 0.6288s/iter; left time: 14743.3316s\n\titers: 300, epoch: 9 | loss: 0.4210406\n\tspeed: 0.6119s/iter; left time: 14286.4784s\n\titers: 400, epoch: 9 | loss: 0.5154567\n\tspeed: 0.5846s/iter; left time: 13590.6254s\n\titers: 500, epoch: 9 | loss: 0.3495531\n\tspeed: 0.5872s/iter; left time: 13592.1135s\nEpoch: 9 cost time: 336.15759348869324\nEpoch: 9, Steps: 563 | Train Loss: 0.5379957 Vali Loss: 0.7774717 Test Loss: 1.2635558\nEarlyStopping counter: 1 out of 10\nUpdating learning rate to 3.90625e-06\n\titers: 100, epoch: 10 | loss: 0.4335171\n\tspeed: 1.3873s/iter; left time: 31886.0143s\n\titers: 200, epoch: 10 | loss: 0.5135459\n\tspeed: 0.5581s/iter; left time: 12771.3029s\n\titers: 300, epoch: 10 | loss: 0.4653003\n\tspeed: 0.4962s/iter; left time: 11304.4578s\n\titers: 400, epoch: 10 | loss: 0.5085408\n\tspeed: 0.5347s/iter; left time: 12128.8002s\n\titers: 500, epoch: 10 | loss: 0.4216959\n\tspeed: 0.6589s/iter; left time: 14881.0997s\nEpoch: 10 cost time: 330.8205261230469\nEpoch: 10, Steps: 563 | Train Loss: 0.5375409 Vali Loss: 0.7722629 Test Loss: 1.2624598\nValidation loss decreased (0.772691 --> 0.772263).  Saving model ...\nUpdating learning rate to 1.953125e-06\n\titers: 100, epoch: 11 | loss: 0.8106416\n\tspeed: 1.2648s/iter; left time: 28357.1317s\n\titers: 200, epoch: 11 | loss: 0.3733309\n\tspeed: 0.5863s/iter; left time: 13087.0832s\n\titers: 300, epoch: 11 | loss: 0.4900924\n\tspeed: 0.5866s/iter; left time: 13035.2458s\n\titers: 400, epoch: 11 | loss: 0.3304124\n\tspeed: 0.5810s/iter; left time: 12852.5656s\n\titers: 500, epoch: 11 | loss: 0.4491582\n\tspeed: 0.5848s/iter; left time: 12878.0292s\nEpoch: 11 cost time: 329.0047826766968\nEpoch: 11, Steps: 563 | Train Loss: 0.5367314 Vali Loss: 0.7699643 Test Loss: 1.2604396\nValidation loss decreased (0.772263 --> 0.769964).  Saving model ...\nUpdating learning rate to 9.765625e-07\n\titers: 100, epoch: 12 | loss: 0.4655216\n\tspeed: 1.2521s/iter; left time: 27369.0699s\n\titers: 200, epoch: 12 | loss: 0.5511262\n\tspeed: 0.5844s/iter; left time: 12714.9062s\n\titers: 300, epoch: 12 | loss: 0.4113804\n\tspeed: 0.5840s/iter; left time: 12649.0447s\n\titers: 400, epoch: 12 | loss: 0.4295128\n\tspeed: 0.5091s/iter; left time: 10976.0539s\n\titers: 500, epoch: 12 | loss: 0.4496293\n\tspeed: 0.5074s/iter; left time: 10887.1631s\nEpoch: 12 cost time: 310.5245885848999\nEpoch: 12, Steps: 563 | Train Loss: 0.5366854 Vali Loss: 0.7716326 Test Loss: 1.2601753\nEarlyStopping counter: 1 out of 10\nUpdating learning rate to 4.8828125e-07\n\titers: 100, epoch: 13 | loss: 0.3879702\n\tspeed: 1.2168s/iter; left time: 25912.2900s\n\titers: 200, epoch: 13 | loss: 0.4208161\n\tspeed: 0.5844s/iter; left time: 12385.8680s\n\titers: 300, epoch: 13 | loss: 0.3421038\n\tspeed: 0.5800s/iter; left time: 12234.6102s\n\titers: 400, epoch: 13 | loss: 0.3854988\n\tspeed: 0.5850s/iter; left time: 12281.8565s\n\titers: 500, epoch: 13 | loss: 0.5360708\n\tspeed: 0.5848s/iter; left time: 12219.9017s\nEpoch: 13 cost time: 328.37229895591736\nEpoch: 13, Steps: 563 | Train Loss: 0.5362176 Vali Loss: 0.7778549 Test Loss: 1.2606558\nEarlyStopping counter: 2 out of 10\nUpdating learning rate to 2.44140625e-07\n\titers: 100, epoch: 14 | loss: 0.4717477\n\tspeed: 1.2494s/iter; left time: 25902.3475s\n\titers: 200, epoch: 14 | loss: 0.3284255\n\tspeed: 0.5858s/iter; left time: 12086.6404s\n\titers: 300, epoch: 14 | loss: 0.4933259\n\tspeed: 0.5857s/iter; left time: 12026.2231s\n\titers: 400, epoch: 14 | loss: 1.0752978\n\tspeed: 0.5843s/iter; left time: 11938.7400s\n\titers: 500, epoch: 14 | loss: 0.4889986\n\tspeed: 0.5868s/iter; left time: 11931.3913s\nEpoch: 14 cost time: 325.16271114349365\nEpoch: 14, Steps: 563 | Train Loss: 0.5357366 Vali Loss: 0.7687548 Test Loss: 1.2605644\nValidation loss decreased (0.769964 --> 0.768755).  Saving model ...\nUpdating learning rate to 1.220703125e-07\n\titers: 100, epoch: 15 | loss: 1.2479489\n\tspeed: 1.0978s/iter; left time: 22141.0416s\n\titers: 200, epoch: 15 | loss: 0.3701240\n\tspeed: 0.5859s/iter; left time: 11758.1126s\n\titers: 300, epoch: 15 | loss: 0.5677407\n\tspeed: 0.5866s/iter; left time: 11713.8399s\n\titers: 400, epoch: 15 | loss: 0.4761855\n\tspeed: 0.5843s/iter; left time: 11608.6954s\n\titers: 500, epoch: 15 | loss: 1.0132579\n\tspeed: 0.5861s/iter; left time: 11587.2804s\nEpoch: 15 cost time: 322.54954862594604\nEpoch: 15, Steps: 563 | Train Loss: 0.5359786 Vali Loss: 0.7724367 Test Loss: 1.2609259\nEarlyStopping counter: 1 out of 10\nUpdating learning rate to 6.103515625e-08\n\titers: 100, epoch: 16 | loss: 0.4538141\n\tspeed: 1.2495s/iter; left time: 24496.7597s\n\titers: 200, epoch: 16 | loss: 0.3707778\n\tspeed: 0.5861s/iter; left time: 11431.7128s\n\titers: 300, epoch: 16 | loss: 0.3868299\n\tspeed: 0.5863s/iter; left time: 11377.2224s\n\titers: 400, epoch: 16 | loss: 0.4375151\n\tspeed: 0.5849s/iter; left time: 11292.2087s\n\titers: 500, epoch: 16 | loss: 0.3164641\n\tspeed: 0.5849s/iter; left time: 11233.0569s\nEpoch: 16 cost time: 329.41551303863525\nEpoch: 16, Steps: 563 | Train Loss: 0.5359336 Vali Loss: 0.7717969 Test Loss: 1.2605718\nEarlyStopping counter: 2 out of 10\nUpdating learning rate to 3.0517578125e-08\n\titers: 100, epoch: 17 | loss: 0.3526658\n\tspeed: 1.2148s/iter; left time: 23133.5914s\n\titers: 200, epoch: 17 | loss: 1.0341094\n\tspeed: 0.4944s/iter; left time: 9365.9134s\n\titers: 300, epoch: 17 | loss: 0.4187870\n\tspeed: 0.5348s/iter; left time: 10077.8991s\n\titers: 400, epoch: 17 | loss: 0.3443227\n\tspeed: 0.5867s/iter; left time: 10996.1183s\n\titers: 500, epoch: 17 | loss: 1.0071056\n\tspeed: 0.5863s/iter; left time: 10931.1983s\nEpoch: 17 cost time: 312.2274739742279\nEpoch: 17, Steps: 563 | Train Loss: 0.5361862 Vali Loss: 0.7715150 Test Loss: 1.2606173\nEarlyStopping counter: 3 out of 10\nUpdating learning rate to 1.52587890625e-08\n\titers: 100, epoch: 18 | loss: 0.4207884\n\tspeed: 1.2498s/iter; left time: 23096.4525s\n\titers: 200, epoch: 18 | loss: 0.5098994\n\tspeed: 0.5868s/iter; left time: 10785.7781s\n\titers: 300, epoch: 18 | loss: 0.5028858\n\tspeed: 0.5866s/iter; left time: 10722.7680s\n\titers: 400, epoch: 18 | loss: 1.0255638\n\tspeed: 0.5866s/iter; left time: 10664.7373s\n\titers: 500, epoch: 18 | loss: 0.4870654\n\tspeed: 0.5863s/iter; left time: 10599.4274s\nEpoch: 18 cost time: 329.97560358047485\nEpoch: 18, Steps: 563 | Train Loss: 0.5360714 Vali Loss: 0.7744815 Test Loss: 1.2605691\nEarlyStopping counter: 4 out of 10\nUpdating learning rate to 7.62939453125e-09\n\titers: 100, epoch: 19 | loss: 0.5029464\n\tspeed: 1.2506s/iter; left time: 22407.7409s\n\titers: 200, epoch: 19 | loss: 0.3943925\n\tspeed: 0.5865s/iter; left time: 10450.4269s\n\titers: 300, epoch: 19 | loss: 0.4491580\n\tspeed: 0.5341s/iter; left time: 9462.6574s\n\titers: 400, epoch: 19 | loss: 0.4983869\n\tspeed: 0.4980s/iter; left time: 8773.5015s\n\titers: 500, epoch: 19 | loss: 0.5493717\n\tspeed: 0.5493s/iter; left time: 9622.1535s\nEpoch: 19 cost time: 312.17646312713623\nEpoch: 19, Steps: 563 | Train Loss: 0.5357661 Vali Loss: 0.7724794 Test Loss: 1.2605894\nEarlyStopping counter: 5 out of 10\nUpdating learning rate to 3.814697265625e-09\n\titers: 100, epoch: 20 | loss: 0.9638261\n\tspeed: 1.2510s/iter; left time: 21709.8330s\n\titers: 200, epoch: 20 | loss: 1.0433729\n\tspeed: 0.5846s/iter; left time: 10087.3038s\n\titers: 300, epoch: 20 | loss: 0.4028158\n\tspeed: 0.5804s/iter; left time: 9956.2633s\n\titers: 400, epoch: 20 | loss: 0.4840755\n\tspeed: 0.5842s/iter; left time: 9962.8077s\n\titers: 500, epoch: 20 | loss: 0.4582183\n\tspeed: 0.5853s/iter; left time: 9923.0749s\nEpoch: 20 cost time: 328.4448871612549\nEpoch: 20, Steps: 563 | Train Loss: 0.5358681 Vali Loss: 0.7712622 Test Loss: 1.2604115\nEarlyStopping counter: 6 out of 10\nUpdating learning rate to 1.9073486328125e-09\n\titers: 100, epoch: 21 | loss: 0.7961905\n\tspeed: 1.2429s/iter; left time: 20868.7328s\n\titers: 200, epoch: 21 | loss: 0.4609322\n\tspeed: 0.5845s/iter; left time: 9755.2372s\n\titers: 300, epoch: 21 | loss: 0.4141016\n\tspeed: 0.5799s/iter; left time: 9620.9793s\n\titers: 400, epoch: 21 | loss: 0.5181958\n\tspeed: 0.5858s/iter; left time: 9661.0266s\n\titers: 500, epoch: 21 | loss: 0.4586566\n\tspeed: 0.5019s/iter; left time: 8227.3193s\nEpoch: 21 cost time: 315.4239761829376\nEpoch: 21, Steps: 563 | Train Loss: 0.5357938 Vali Loss: 0.7730366 Test Loss: 1.2605349\nEarlyStopping counter: 7 out of 10\nUpdating learning rate to 9.5367431640625e-10\n\titers: 100, epoch: 22 | loss: 0.5260513\n\tspeed: 1.1601s/iter; left time: 18825.9548s\n\titers: 200, epoch: 22 | loss: 0.3734488\n\tspeed: 0.5852s/iter; left time: 9437.9470s\n\titers: 300, epoch: 22 | loss: 0.4082041\n\tspeed: 0.5832s/iter; left time: 9347.2207s\n\titers: 400, epoch: 22 | loss: 0.4714894\n\tspeed: 0.5848s/iter; left time: 9314.9948s\n\titers: 500, epoch: 22 | loss: 0.4158726\n\tspeed: 0.5848s/iter; left time: 9255.7051s\nEpoch: 22 cost time: 328.6732380390167\nEpoch: 22, Steps: 563 | Train Loss: 0.5358477 Vali Loss: 0.7718872 Test Loss: 1.2605044\nEarlyStopping counter: 8 out of 10\nUpdating learning rate to 4.76837158203125e-10\n\titers: 100, epoch: 23 | loss: 0.4028161\n\tspeed: 1.2443s/iter; left time: 19491.2564s\n\titers: 200, epoch: 23 | loss: 0.4247462\n\tspeed: 0.5823s/iter; left time: 9062.7677s\n\titers: 300, epoch: 23 | loss: 0.4729501\n\tspeed: 0.5733s/iter; left time: 8865.5455s\n\titers: 400, epoch: 23 | loss: 0.4763953\n\tspeed: 0.5793s/iter; left time: 8901.4380s\n\titers: 500, epoch: 23 | loss: 0.4221975\n\tspeed: 0.5837s/iter; left time: 8910.5104s\nEpoch: 23 cost time: 326.43708848953247\nEpoch: 23, Steps: 563 | Train Loss: 0.5361530 Vali Loss: 0.7709157 Test Loss: 1.2603928\nEarlyStopping counter: 9 out of 10\nUpdating learning rate to 2.384185791015625e-10\n\titers: 100, epoch: 24 | loss: 0.4883726\n\tspeed: 1.1309s/iter; left time: 17078.7190s\n\titers: 200, epoch: 24 | loss: 0.3658566\n\tspeed: 0.4688s/iter; left time: 7033.2867s\n\titers: 300, epoch: 24 | loss: 0.4336012\n\tspeed: 0.4775s/iter; left time: 7115.3979s\n\titers: 400, epoch: 24 | loss: 0.4195312\n\tspeed: 0.2847s/iter; left time: 4214.3693s\n\titers: 500, epoch: 24 | loss: 0.3804596\n\tspeed: 0.2695s/iter; left time: 3961.5035s\nEpoch: 24 cost time: 216.0749273300171\nEpoch: 24, Steps: 563 | Train Loss: 0.5360778 Vali Loss: 0.7712029 Test Loss: 1.2607926\nEarlyStopping counter: 10 out of 10\nEarly stopping\n>>>>>>>testing : long_term_forecast_PatchTST_weather_50_PatchTST_custom_ftM_sl336_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_robustness_datavolume_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\ntest 5174\ntest shape: (5174, 96, 21) (5174, 96, 21)\ntest shape: (5174, 96, 21) (5174, 96, 21)\nmse:1.2607773542404175, mae:0.5204442739486694, dtw:Not calculated\n","output_type":"stream"}],"outputs_reference":"s3:deepnote-cell-outputs-production/58038db3-74e9-4222-9633-1813a70356d1","content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=25aca1a4-5304-4528-85ec-154f53dfeb1c' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_persisted_session":{"createdAt":"2025-04-17T17:54:44.312Z"},"deepnote_notebook_id":"d2c8056721b9470686d3d3bd9e7d5361"}}